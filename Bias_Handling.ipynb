{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4e89f1de",
   "metadata": {},
   "source": [
    "### Bias Detection and Handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "86ef4e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# df = pd.read_pickle('Data/df_cleaned.pkl')\n",
    "\n",
    "import sys\n",
    "import numpy as np\n",
    "import types\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('Data/df_cleaned_v2.csv', index_col=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3ad55b36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9757, 47)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d2412757",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns='zero_count',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bda33f36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "General_hearing_condition                          0\n",
       "Had_high_blood_pressure                            0\n",
       "WBC                                                0\n",
       "Haemoglobin                                        0\n",
       "Platelete                                          0\n",
       "Gender                                             0\n",
       "Age                                                0\n",
       "Race_Ethnicity                                     0\n",
       "Country_of_Birth                                   0\n",
       "Education_Level                                    0\n",
       "Marital_Status                                     0\n",
       "Household_Size                                     0\n",
       "Income_to_Poverty_Ratio                            0\n",
       "Has_diabetes                                       0\n",
       "Takes_vitamin_supplements                          0\n",
       "Has_Disability                                     0\n",
       "HDL_mg                                             0\n",
       "Has_Hepatitis                                      0\n",
       "Covered_by_health_insurance                        0\n",
       "Tested_for_HIV_Virus                               0\n",
       "General_health_condition                           0\n",
       "Received_Hepatitis_A_Vaccine                       0\n",
       "Family_poverty_level_index                         0\n",
       "Has_Kidney_Failure                                 0\n",
       "Had_Asthma                                         0\n",
       "Had_Arthritis                                      0\n",
       "Had_heart_attack                                   0\n",
       "Had_Thyroid                                        0\n",
       "Had_Liver_COndition                                0\n",
       "Had_Cancer                                         0\n",
       "Teeth_and_gum_health                               0\n",
       "Number_of_Moderate_Physical_activities_per_week    0\n",
       "Number_of_Vigorous_Physical_activities_per_week    0\n",
       "Number_of_hours_of_sleep                           0\n",
       "Cholestrol_level                                   0\n",
       "SystolicBP                                         0\n",
       "DiastolicBP                                        0\n",
       "Pulse                                              0\n",
       "BODY_MEASURE_COMPOSITE                             0\n",
       "blood_macros                                       0\n",
       "mean_steroid_ng_dl                                 0\n",
       "balance_symptom_score                              0\n",
       "balance_impact_score                               0\n",
       "fall_risk_score                                    0\n",
       "functional_difficulty_composite                    0\n",
       "Age_Group                                          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea16b0bb",
   "metadata": {},
   "source": [
    "Check 1: Demographic Representation (Visualization)\n",
    "Purpose: Ensure no group is severely underrepresented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a48f783c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['No difficulty', 'Some difficulty', 'A lot of difficulty',\n",
       "       'Very Severe Difficulty'], dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['functional_difficulty_composite'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "67f07034",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['General_hearing_condition', 'Had_high_blood_pressure', 'WBC',\n",
       "       'Haemoglobin', 'Platelete', 'Gender', 'Age', 'Race_Ethnicity',\n",
       "       'Country_of_Birth', 'Education_Level', 'Marital_Status',\n",
       "       'Household_Size', 'Income_to_Poverty_Ratio', 'Has_diabetes',\n",
       "       'Takes_vitamin_supplements', 'Has_Disability', 'HDL_mg',\n",
       "       'Has_Hepatitis', 'Covered_by_health_insurance', 'Tested_for_HIV_Virus',\n",
       "       'General_health_condition', 'Received_Hepatitis_A_Vaccine',\n",
       "       'Family_poverty_level_index', 'Has_Kidney_Failure', 'Had_Asthma',\n",
       "       'Had_Arthritis', 'Had_heart_attack', 'Had_Thyroid',\n",
       "       'Had_Liver_COndition', 'Had_Cancer', 'Teeth_and_gum_health',\n",
       "       'Number_of_Moderate_Physical_activities_per_week',\n",
       "       'Number_of_Vigorous_Physical_activities_per_week',\n",
       "       'Number_of_hours_of_sleep', 'Cholestrol_level', 'SystolicBP',\n",
       "       'DiastolicBP', 'Pulse', 'BODY_MEASURE_COMPOSITE', 'blood_macros',\n",
       "       'mean_steroid_ng_dl', 'balance_symptom_score', 'balance_impact_score',\n",
       "       'fall_risk_score', 'functional_difficulty_composite', 'Age_Group'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "26dcebc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "\n",
    "# Assuming your dataframe is named 'df'\n",
    "# df = pd.read_csv('your_nhanes_data.csv')\n",
    "\n",
    "def analyze_representation_bias(df):\n",
    "    \"\"\"\n",
    "    Analyze demographic representation to identify potential sampling bias\n",
    "    \"\"\"\n",
    "    print(\"=\" * 80)\n",
    "    print(\"1. REPRESENTATION BIAS ANALYSIS\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    demographic_cols = ['Gender', 'Race_Ethnicity', 'Age_Group', 'Education_Level', \n",
    "                        'Marital_Status', 'Country_of_Birth']\n",
    "    \n",
    "    for col in demographic_cols:\n",
    "        if col in df.columns:\n",
    "            print(f\"\\n{col} Distribution:\")\n",
    "            print(\"-\" * 40)\n",
    "            counts = df[col].value_counts(dropna=False)\n",
    "            percentages = df[col].value_counts(normalize=True, dropna=False) * 100\n",
    "            \n",
    "            result_df = pd.DataFrame({\n",
    "                'Count': counts,\n",
    "                'Percentage': percentages.round(2)\n",
    "            })\n",
    "            print(result_df)\n",
    "            \n",
    "            # Check for severe underrepresentation (< 5%)\n",
    "            underrepresented = percentages[percentages < 5]\n",
    "            if len(underrepresented) > 0:\n",
    "                print(f\"\\n⚠️  WARNING: Underrepresented groups (< 5%):\")\n",
    "                for group, pct in underrepresented.items():\n",
    "                    print(f\"   - {group}: {pct:.2f}%\")\n",
    "\n",
    "\n",
    "def analyze_outcome_disparities(df):\n",
    "    \"\"\"\n",
    "    Analyze health outcome disparities across demographic groups\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"3. HEALTH OUTCOME DISPARITY ANALYSIS\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    # Conditions to analyze\n",
    "    conditions = ['Has_diabetes', 'Has_high_blood_pressure', 'Had_heart_attack', \n",
    "                  'Had_Cancer', 'Had_Asthma', 'General_health_condition']\n",
    "    \n",
    "    demographic_cols = ['Gender', 'Race_Ethnicity', 'Age_Group']\n",
    "    \n",
    "    for condition in conditions:\n",
    "        if condition not in df.columns:\n",
    "            continue\n",
    "            \n",
    "        print(f\"\\n{condition}:\")\n",
    "        print(\"-\" * 40)\n",
    "        \n",
    "        for demo_col in demographic_cols:\n",
    "            if demo_col not in df.columns:\n",
    "                continue\n",
    "                \n",
    "            if condition == 'General_health_condition':\n",
    "                # For ordinal health condition, calculate mean rating\n",
    "                health_order = ['Excellent', 'Very good', 'Good', 'Fair', 'Poor']\n",
    "                temp_df = df[df[condition].isin(health_order)].copy()\n",
    "                temp_df['health_score'] = temp_df[condition].map(\n",
    "                    {h: i for i, h in enumerate(health_order)}\n",
    "                )\n",
    "                by_group = temp_df.groupby(demo_col)['health_score'].mean()\n",
    "                print(f\"\\n  {demo_col} (lower score = better health):\")\n",
    "                print(f\"  {by_group.round(2).to_dict()}\")\n",
    "            else:\n",
    "                # For binary conditions\n",
    "                by_group = df.groupby(demo_col)[condition].apply(\n",
    "                    lambda x: (x == 'Yes').sum() / x.notna().sum() * 100\n",
    "                )\n",
    "                print(f\"\\n  {demo_col} (% with condition):\")\n",
    "                print(f\"  {by_group.round(2).to_dict()}\")\n",
    "\n",
    "\n",
    "def analyze_continuous_health_metrics(df):\n",
    "    \"\"\"\n",
    "    Analyze continuous health metrics for disparities\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"4. CONTINUOUS HEALTH METRICS ANALYSIS\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    metrics = ['SystolicBP', 'DiastolicBP', 'Cholestrol_level', \n",
    "               'HDL_mg', 'WBC', 'Haemoglobin']\n",
    "    demographic_cols = ['Gender', 'Race_Ethnicity']\n",
    "    \n",
    "    for metric in metrics:\n",
    "        if metric not in df.columns:\n",
    "            continue\n",
    "            \n",
    "        print(f\"\\n{metric}:\")\n",
    "        print(\"-\" * 40)\n",
    "        \n",
    "        for demo_col in demographic_cols:\n",
    "            if demo_col not in df.columns:\n",
    "                continue\n",
    "                \n",
    "            print(f\"\\n  By {demo_col}:\")\n",
    "            by_group = df.groupby(demo_col)[metric].agg(['mean', 'std', 'count'])\n",
    "            print(f\"  {by_group.round(2)}\")\n",
    "            \n",
    "            # Perform statistical test (ANOVA)\n",
    "            groups = [group[metric].dropna() for name, group in df.groupby(demo_col)]\n",
    "            if len(groups) > 1 and all(len(g) > 0 for g in groups):\n",
    "                f_stat, p_value = stats.f_oneway(*groups)\n",
    "                if p_value < 0.05:\n",
    "                    print(f\"  ⚠️  Significant difference detected (p={p_value:.4f})\")\n",
    "\n",
    "\n",
    "def analyze_socioeconomic_bias(df):\n",
    "    \"\"\"\n",
    "    Analyze potential socioeconomic biases\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"5. SOCIOECONOMIC BIAS ANALYSIS\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    if 'Income_to_Poverty_Ratio' in df.columns:\n",
    "        # Create income categories\n",
    "        df_temp = df.copy()\n",
    "        df_temp['Income_Category'] = pd.cut(\n",
    "            df_temp['Income_to_Poverty_Ratio'],\n",
    "            bins=[0, 1.3, 3.5, 10],\n",
    "            labels=['Below Poverty', 'Low Income', 'Above Low Income']\n",
    "        )\n",
    "        \n",
    "        print(\"\\nIncome Category Distribution:\")\n",
    "        print(df_temp['Income_Category'].value_counts(normalize=True) * 100)\n",
    "        \n",
    "        # Health insurance coverage by income\n",
    "        if 'Covered_by_health_insurance' in df.columns:\n",
    "            print(\"\\nHealth Insurance Coverage by Income:\")\n",
    "            coverage = pd.crosstab(\n",
    "                df_temp['Income_Category'],\n",
    "                df_temp['Covered_by_health_insurance'],\n",
    "                normalize='index'\n",
    "            ) * 100\n",
    "            print(coverage.round(2))\n",
    "        \n",
    "        # Health outcomes by income\n",
    "        if 'General_health_condition' in df.columns:\n",
    "            print(\"\\nGeneral Health by Income:\")\n",
    "            health = pd.crosstab(\n",
    "                df_temp['Income_Category'],\n",
    "                df_temp['General_health_condition'],\n",
    "                normalize='index'\n",
    "            ) * 100\n",
    "            print(health.round(2))\n",
    "    \n",
    "\n",
    "\n",
    "# Run the analysis\n",
    "# generate_bias_report(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "03d0e218",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "1. REPRESENTATION BIAS ANALYSIS\n",
      "================================================================================\n",
      "\n",
      "Gender Distribution:\n",
      "----------------------------------------\n",
      "        Count  Percentage\n",
      "Gender                   \n",
      "Female   5301       54.33\n",
      "Male     4456       45.67\n",
      "\n",
      "Race_Ethnicity Distribution:\n",
      "----------------------------------------\n",
      "                                     Count  Percentage\n",
      "Race_Ethnicity                                        \n",
      "Non-Hispanic White                    5321       54.54\n",
      "Non-Hispanic Black                    1277       13.09\n",
      "Other Race - Including Multi-Racial   1239       12.70\n",
      "Other Hispanic                        1079       11.06\n",
      "Mexican American                       841        8.62\n",
      "\n",
      "Age_Group Distribution:\n",
      "----------------------------------------\n",
      "           Count  Percentage\n",
      "Age_Group                   \n",
      "61-75       2494       25.56\n",
      "31-45       1749       17.93\n",
      "0-18        1680       17.22\n",
      "46-60       1627       16.68\n",
      "19-30       1235       12.66\n",
      "76+          972        9.96\n",
      "\n",
      "Education_Level Distribution:\n",
      "----------------------------------------\n",
      "                                                    Count  Percentage\n",
      "Education_Level                                                      \n",
      "Some college or AA degree                            2692       27.59\n",
      "College graduate or above                            2621       26.86\n",
      "High school graduate/GED or equivalent               1727       17.70\n",
      "Unknown/NA                                           1690       17.32\n",
      "9-11th grade (Includes 12th grade with no diploma)    657        6.73\n",
      "Less than 9th grade                                   370        3.79\n",
      "\n",
      "⚠️  WARNING: Underrepresented groups (< 5%):\n",
      "   - Less than 9th grade: 3.79%\n",
      "\n",
      "Marital_Status Distribution:\n",
      "----------------------------------------\n",
      "                             Count  Percentage\n",
      "Marital_Status                                \n",
      "Married/Living with partner   4114       42.16\n",
      "Widowed/Divorced/Separated    2003       20.53\n",
      "Never married                 1951       20.00\n",
      "Unknown/NA                    1689       17.31\n",
      "\n",
      "Country_of_Birth Distribution:\n",
      "----------------------------------------\n",
      "                                    Count  Percentage\n",
      "Country_of_Birth                                     \n",
      "Born in 50 US states or Washington   7978       81.77\n",
      "Unknown/NA                           1779       18.23\n",
      "\n",
      "================================================================================\n",
      "3. HEALTH OUTCOME DISPARITY ANALYSIS\n",
      "================================================================================\n",
      "\n",
      "Has_diabetes:\n",
      "----------------------------------------\n",
      "\n",
      "  Gender (% with condition):\n",
      "  {'Female': 10.45, 'Male': 11.56}\n",
      "\n",
      "  Race_Ethnicity (% with condition):\n",
      "  {'Mexican American': 10.7, 'Non-Hispanic Black': 14.88, 'Non-Hispanic White': 10.17, 'Other Hispanic': 10.66, 'Other Race - Including Multi-Racial': 10.73}\n",
      "\n",
      "  Age_Group (% with condition):\n",
      "  {'0-18': 0.3, '19-30': 1.46, '31-45': 4.12, '46-60': 15.61, '61-75': 20.49, '76+': 21.5}\n",
      "\n",
      "Had_heart_attack:\n",
      "----------------------------------------\n",
      "\n",
      "  Gender (% with condition):\n",
      "  {'Female': 2.21, 'Male': 4.71}\n",
      "\n",
      "  Race_Ethnicity (% with condition):\n",
      "  {'Mexican American': 0.83, 'Non-Hispanic Black': 2.82, 'Non-Hispanic White': 4.02, 'Other Hispanic': 3.15, 'Other Race - Including Multi-Racial': 2.91}\n",
      "\n",
      "  Age_Group (% with condition):\n",
      "  {'0-18': 0.0, '19-30': 0.16, '31-45': 0.69, '46-60': 2.7, '61-75': 6.5, '76+': 11.01}\n",
      "\n",
      "Had_Cancer:\n",
      "----------------------------------------\n",
      "\n",
      "  Gender (% with condition):\n",
      "  {'Female': 12.43, 'Male': 11.33}\n",
      "\n",
      "  Race_Ethnicity (% with condition):\n",
      "  {'Mexican American': 2.85, 'Non-Hispanic Black': 6.89, 'Non-Hispanic White': 16.71, 'Other Hispanic': 5.47, 'Other Race - Including Multi-Racial': 8.39}\n",
      "\n",
      "  Age_Group (% with condition):\n",
      "  {'0-18': 0.0, '19-30': 0.73, '31-45': 2.86, '46-60': 9.04, '61-75': 24.46, '76+': 35.8}\n",
      "\n",
      "Had_Asthma:\n",
      "----------------------------------------\n",
      "\n",
      "  Gender (% with condition):\n",
      "  {'Female': 19.11, 'Male': 16.72}\n",
      "\n",
      "  Race_Ethnicity (% with condition):\n",
      "  {'Mexican American': 13.56, 'Non-Hispanic Black': 20.44, 'Non-Hispanic White': 17.52, 'Other Hispanic': 20.3, 'Other Race - Including Multi-Racial': 18.72}\n",
      "\n",
      "  Age_Group (% with condition):\n",
      "  {'0-18': 17.08, '19-30': 23.24, '31-45': 18.64, '46-60': 19.61, '61-75': 16.12, '76+': 14.09}\n",
      "\n",
      "General_health_condition:\n",
      "----------------------------------------\n",
      "\n",
      "  Gender (lower score = better health):\n",
      "  {'Female': 1.53, 'Male': 1.46}\n",
      "\n",
      "  Race_Ethnicity (lower score = better health):\n",
      "  {'Mexican American': 1.58, 'Non-Hispanic Black': 1.55, 'Non-Hispanic White': 1.45, 'Other Hispanic': 1.6, 'Other Race - Including Multi-Racial': 1.48}\n",
      "\n",
      "  Age_Group (lower score = better health):\n",
      "  {'0-18': 0.88, '19-30': 1.29, '31-45': 1.46, '46-60': 1.75, '61-75': 1.75, '76+': 1.84}\n",
      "\n",
      "================================================================================\n",
      "4. CONTINUOUS HEALTH METRICS ANALYSIS\n",
      "================================================================================\n",
      "\n",
      "SystolicBP:\n",
      "----------------------------------------\n",
      "\n",
      "  By Gender:\n",
      "            mean    std  count\n",
      "Gender                      \n",
      "Female  117.54  16.80   5301\n",
      "Male    120.47  15.73   4456\n",
      "  ⚠️  Significant difference detected (p=0.0000)\n",
      "\n",
      "  By Race_Ethnicity:\n",
      "                                         mean    std  count\n",
      "Race_Ethnicity                                           \n",
      "Mexican American                     114.42  14.25    841\n",
      "Non-Hispanic Black                   120.66  18.40   1277\n",
      "Non-Hispanic White                   119.93  15.95   5321\n",
      "Other Hispanic                       116.10  15.87   1079\n",
      "Other Race - Including Multi-Racial  117.98  16.97   1239\n",
      "  ⚠️  Significant difference detected (p=0.0000)\n",
      "\n",
      "DiastolicBP:\n",
      "----------------------------------------\n",
      "\n",
      "  By Gender:\n",
      "           mean    std  count\n",
      "Gender                     \n",
      "Female  71.88  10.00   5301\n",
      "Male    72.35  10.54   4456\n",
      "  ⚠️  Significant difference detected (p=0.0227)\n",
      "\n",
      "  By Race_Ethnicity:\n",
      "                                        mean    std  count\n",
      "Race_Ethnicity                                          \n",
      "Mexican American                     69.54  10.15    841\n",
      "Non-Hispanic Black                   73.75  11.35   1277\n",
      "Non-Hispanic White                   72.40   9.92   5321\n",
      "Other Hispanic                       70.80   9.91   1079\n",
      "Other Race - Including Multi-Racial  71.93  10.40   1239\n",
      "  ⚠️  Significant difference detected (p=0.0000)\n",
      "\n",
      "Cholestrol_level:\n",
      "----------------------------------------\n",
      "\n",
      "  By Gender:\n",
      "            mean    std  count\n",
      "Gender                      \n",
      "Female  183.47  36.25   5301\n",
      "Male    176.13  36.18   4456\n",
      "  ⚠️  Significant difference detected (p=0.0000)\n",
      "\n",
      "  By Race_Ethnicity:\n",
      "                                         mean    std  count\n",
      "Race_Ethnicity                                           \n",
      "Mexican American                     174.42  33.88    841\n",
      "Non-Hispanic Black                   174.35  32.53   1277\n",
      "Non-Hispanic White                   182.67  37.06   5321\n",
      "Other Hispanic                       177.08  37.17   1079\n",
      "Other Race - Including Multi-Racial  181.63  37.05   1239\n",
      "  ⚠️  Significant difference detected (p=0.0000)\n",
      "\n",
      "HDL_mg:\n",
      "----------------------------------------\n",
      "\n",
      "  By Gender:\n",
      "           mean    std  count\n",
      "Gender                     \n",
      "Female  55.97  12.26   5301\n",
      "Male    50.55  10.56   4456\n",
      "  ⚠️  Significant difference detected (p=0.0000)\n",
      "\n",
      "  By Race_Ethnicity:\n",
      "                                        mean    std  count\n",
      "Race_Ethnicity                                          \n",
      "Mexican American                     50.90   9.71    841\n",
      "Non-Hispanic Black                   53.75  11.48   1277\n",
      "Non-Hispanic White                   54.10  12.31   5321\n",
      "Other Hispanic                       52.03  10.45   1079\n",
      "Other Race - Including Multi-Racial  53.72  12.15   1239\n",
      "  ⚠️  Significant difference detected (p=0.0000)\n",
      "\n",
      "WBC:\n",
      "----------------------------------------\n",
      "\n",
      "  By Gender:\n",
      "          mean   std  count\n",
      "Gender                   \n",
      "Female  6.92  1.76   5301\n",
      "Male    6.79  1.72   4456\n",
      "  ⚠️  Significant difference detected (p=0.0005)\n",
      "\n",
      "  By Race_Ethnicity:\n",
      "                                       mean   std  count\n",
      "Race_Ethnicity                                        \n",
      "Mexican American                     7.01  1.66    841\n",
      "Non-Hispanic Black                   6.44  1.66   1277\n",
      "Non-Hispanic White                   6.91  1.76   5321\n",
      "Other Hispanic                       6.98  1.76   1079\n",
      "Other Race - Including Multi-Racial  6.87  1.73   1239\n",
      "  ⚠️  Significant difference detected (p=0.0000)\n",
      "\n",
      "Haemoglobin:\n",
      "----------------------------------------\n",
      "\n",
      "  By Gender:\n",
      "           mean   std  count\n",
      "Gender                    \n",
      "Female  13.30  1.11   5301\n",
      "Male    14.35  1.24   4456\n",
      "  ⚠️  Significant difference detected (p=0.0000)\n",
      "\n",
      "  By Race_Ethnicity:\n",
      "                                        mean   std  count\n",
      "Race_Ethnicity                                         \n",
      "Mexican American                     13.74  1.41    841\n",
      "Non-Hispanic Black                   13.22  1.35   1277\n",
      "Non-Hispanic White                   13.95  1.19   5321\n",
      "Other Hispanic                       13.61  1.32   1079\n",
      "Other Race - Including Multi-Racial  13.79  1.27   1239\n",
      "  ⚠️  Significant difference detected (p=0.0000)\n",
      "\n",
      "================================================================================\n",
      "5. SOCIOECONOMIC BIAS ANALYSIS\n",
      "================================================================================\n",
      "\n",
      "Income Category Distribution:\n",
      "Income_Category\n",
      "Low Income          47.606846\n",
      "Above Low Income    30.859895\n",
      "Below Poverty       21.533258\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Health Insurance Coverage by Income:\n",
      "Covered_by_health_insurance     No  Unknown/NA    Yes\n",
      "Income_Category                                      \n",
      "Below Poverty                13.85        0.33  85.82\n",
      "Low Income                    8.93        0.37  90.70\n",
      "Above Low Income              2.29        0.10  97.61\n",
      "\n",
      "General Health by Income:\n",
      "General_health_condition  Don't know  Excellent   Fair   Good  Poor  Very good\n",
      "Income_Category                                                               \n",
      "Below Poverty                   0.00      18.37  21.94  32.03  5.38      22.28\n",
      "Low Income                      0.04      18.04  13.97  34.96  3.25      29.73\n",
      "Above Low Income                0.03      22.09   7.34  28.50  1.46      40.58\n"
     ]
    }
   ],
   "source": [
    "analyze_representation_bias(df)\n",
    "analyze_outcome_disparities(df)\n",
    "analyze_continuous_health_metrics(df)\n",
    "analyze_socioeconomic_bias(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "750b69fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1: Targeted oversampling for underrepresented groups...\n",
      "Oversampled 'Mexican American': 841 → 975 (8.62% → 10.00%)\n",
      "Oversampled 'Less than 9th grade': 388 → 989 (3.92% → 10.00%)\n",
      "\n",
      "Original df shape: (9757, 46)\n",
      "Oversampled df shape: (10492, 46)\n",
      "\n",
      "==================================================\n",
      "NEW DISTRIBUTIONS AFTER OVERSAMPLING\n",
      "==================================================\n",
      "\n",
      "Race_Ethnicity Distribution:\n",
      "Race_Ethnicity\n",
      "Non-Hispanic White                     5440\n",
      "Non-Hispanic Black                     1333\n",
      "Other Race - Including Multi-Racial    1295\n",
      "Other Hispanic                         1254\n",
      "Mexican American                       1170\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Education_Level Distribution:\n",
      "Education_Level\n",
      "Some college or AA degree                             2725\n",
      "College graduate or above                             2635\n",
      "High school graduate/GED or equivalent                1744\n",
      "Unknown/NA                                            1732\n",
      "Less than 9th grade                                    989\n",
      "9-11th grade (Includes 12th grade with no diploma)     667\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>General_hearing_condition</th>\n",
       "      <th>Had_high_blood_pressure</th>\n",
       "      <th>WBC</th>\n",
       "      <th>Haemoglobin</th>\n",
       "      <th>Platelete</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Race_Ethnicity</th>\n",
       "      <th>Country_of_Birth</th>\n",
       "      <th>Education_Level</th>\n",
       "      <th>...</th>\n",
       "      <th>DiastolicBP</th>\n",
       "      <th>Pulse</th>\n",
       "      <th>BODY_MEASURE_COMPOSITE</th>\n",
       "      <th>blood_macros</th>\n",
       "      <th>mean_steroid_ng_dl</th>\n",
       "      <th>balance_symptom_score</th>\n",
       "      <th>balance_impact_score</th>\n",
       "      <th>fall_risk_score</th>\n",
       "      <th>functional_difficulty_composite</th>\n",
       "      <th>Age_Group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Excellent</td>\n",
       "      <td>Yes</td>\n",
       "      <td>4.7</td>\n",
       "      <td>15.7</td>\n",
       "      <td>259.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>43.0</td>\n",
       "      <td>Other Race - Including Multi-Racial</td>\n",
       "      <td>Unknown/NA</td>\n",
       "      <td>College graduate or above</td>\n",
       "      <td>...</td>\n",
       "      <td>96.000000</td>\n",
       "      <td>81.000000</td>\n",
       "      <td>0.614546</td>\n",
       "      <td>0.047064</td>\n",
       "      <td>0.351579</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>No difficulty</td>\n",
       "      <td>31-45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Moderate hearing trouble</td>\n",
       "      <td>Yes</td>\n",
       "      <td>6.3</td>\n",
       "      <td>15.2</td>\n",
       "      <td>221.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>66.0</td>\n",
       "      <td>Non-Hispanic White</td>\n",
       "      <td>Born in 50 US states or Washington</td>\n",
       "      <td>College graduate or above</td>\n",
       "      <td>...</td>\n",
       "      <td>78.666667</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>0.508978</td>\n",
       "      <td>1.166786</td>\n",
       "      <td>0.065015</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Some difficulty</td>\n",
       "      <td>61-75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Moderate hearing trouble</td>\n",
       "      <td>No</td>\n",
       "      <td>5.7</td>\n",
       "      <td>13.8</td>\n",
       "      <td>235.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>44.0</td>\n",
       "      <td>Other Hispanic</td>\n",
       "      <td>Unknown/NA</td>\n",
       "      <td>High school graduate/GED or equivalent</td>\n",
       "      <td>...</td>\n",
       "      <td>78.333333</td>\n",
       "      <td>81.333333</td>\n",
       "      <td>0.087322</td>\n",
       "      <td>-0.121560</td>\n",
       "      <td>0.070373</td>\n",
       "      <td>6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>Some difficulty</td>\n",
       "      <td>31-45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Good</td>\n",
       "      <td>No</td>\n",
       "      <td>6.8</td>\n",
       "      <td>13.9</td>\n",
       "      <td>264.5</td>\n",
       "      <td>Male</td>\n",
       "      <td>43.0</td>\n",
       "      <td>Mexican American</td>\n",
       "      <td>Unknown/NA</td>\n",
       "      <td>9-11th grade (Includes 12th grade with no dipl...</td>\n",
       "      <td>...</td>\n",
       "      <td>74.333333</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>0.318792</td>\n",
       "      <td>-0.049170</td>\n",
       "      <td>0.216401</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>No difficulty</td>\n",
       "      <td>31-45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Good</td>\n",
       "      <td>No</td>\n",
       "      <td>6.5</td>\n",
       "      <td>14.0</td>\n",
       "      <td>241.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>65.0</td>\n",
       "      <td>Non-Hispanic White</td>\n",
       "      <td>Born in 50 US states or Washington</td>\n",
       "      <td>High school graduate/GED or equivalent</td>\n",
       "      <td>...</td>\n",
       "      <td>74.000000</td>\n",
       "      <td>69.333333</td>\n",
       "      <td>0.249125</td>\n",
       "      <td>-0.012353</td>\n",
       "      <td>-0.274090</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>No difficulty</td>\n",
       "      <td>61-75</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 46 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  General_hearing_condition Had_high_blood_pressure  WBC  Haemoglobin  \\\n",
       "0                 Excellent                     Yes  4.7         15.7   \n",
       "1  Moderate hearing trouble                     Yes  6.3         15.2   \n",
       "2  Moderate hearing trouble                      No  5.7         13.8   \n",
       "3                      Good                      No  6.8         13.9   \n",
       "4                      Good                      No  6.5         14.0   \n",
       "\n",
       "   Platelete  Gender   Age                       Race_Ethnicity  \\\n",
       "0      259.0    Male  43.0  Other Race - Including Multi-Racial   \n",
       "1      221.0    Male  66.0                   Non-Hispanic White   \n",
       "2      235.0  Female  44.0                       Other Hispanic   \n",
       "3      264.5    Male  43.0                     Mexican American   \n",
       "4      241.0  Female  65.0                   Non-Hispanic White   \n",
       "\n",
       "                     Country_of_Birth  \\\n",
       "0                          Unknown/NA   \n",
       "1  Born in 50 US states or Washington   \n",
       "2                          Unknown/NA   \n",
       "3                          Unknown/NA   \n",
       "4  Born in 50 US states or Washington   \n",
       "\n",
       "                                     Education_Level  ... DiastolicBP  \\\n",
       "0                          College graduate or above  ...   96.000000   \n",
       "1                          College graduate or above  ...   78.666667   \n",
       "2             High school graduate/GED or equivalent  ...   78.333333   \n",
       "3  9-11th grade (Includes 12th grade with no dipl...  ...   74.333333   \n",
       "4             High school graduate/GED or equivalent  ...   74.000000   \n",
       "\n",
       "       Pulse  BODY_MEASURE_COMPOSITE blood_macros mean_steroid_ng_dl  \\\n",
       "0  81.000000                0.614546     0.047064           0.351579   \n",
       "1  72.000000                0.508978     1.166786           0.065015   \n",
       "2  81.333333                0.087322    -0.121560           0.070373   \n",
       "3  72.000000                0.318792    -0.049170           0.216401   \n",
       "4  69.333333                0.249125    -0.012353          -0.274090   \n",
       "\n",
       "  balance_symptom_score  balance_impact_score fall_risk_score  \\\n",
       "0                     0                   0.0             0.0   \n",
       "1                     0                   0.0             0.0   \n",
       "2                     6                   1.0             3.5   \n",
       "3                     0                   0.0             0.0   \n",
       "4                     0                   0.0             0.0   \n",
       "\n",
       "  functional_difficulty_composite Age_Group  \n",
       "0                   No difficulty     31-45  \n",
       "1                 Some difficulty     61-75  \n",
       "2                 Some difficulty     31-45  \n",
       "3                   No difficulty     31-45  \n",
       "4                   No difficulty     61-75  \n",
       "\n",
       "[5 rows x 46 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# ============================================================================\n",
    "# TARGETED OVERSAMPLING FOR UNDERREPRESENTED GROUPS\n",
    "# ============================================================================\n",
    "\n",
    "print(\"Step 1: Targeted oversampling for underrepresented groups...\")\n",
    "\n",
    "# Define target percentages for underrepresented groups\n",
    "target_percentages = {\n",
    "    'Race_Ethnicity': {\n",
    "        'Mexican American': 0.10  # Target 10%\n",
    "    },\n",
    "    'Education_Level': {\n",
    "        'Less than 9th grade': 0.10  # Target 10%\n",
    "    }\n",
    "}\n",
    "\n",
    "df_oversampled = df.copy()\n",
    "\n",
    "# Oversample Race_Ethnicity groups\n",
    "for group, target_pct in target_percentages['Race_Ethnicity'].items():\n",
    "    current_count = len(df[df['Race_Ethnicity'] == group])\n",
    "    current_pct = current_count / len(df)\n",
    "    \n",
    "    if current_pct < target_pct:\n",
    "        # Calculate how many additional samples needed\n",
    "        target_count = int(len(df) * target_pct)\n",
    "        additional_samples = target_count - current_count\n",
    "        \n",
    "        # Oversample with replacement\n",
    "        group_data = df[df['Race_Ethnicity'] == group]\n",
    "        oversampled = group_data.sample(n=additional_samples, replace=True, random_state=42)\n",
    "        df_oversampled = pd.concat([df_oversampled, oversampled], ignore_index=True)\n",
    "        \n",
    "        print(f\"Oversampled '{group}': {current_count} → {target_count} ({current_pct:.2%} → {target_pct:.2%})\")\n",
    "\n",
    "# Oversample Education_Level groups\n",
    "for group, target_pct in target_percentages['Education_Level'].items():\n",
    "    current_count = len(df_oversampled[df_oversampled['Education_Level'] == group])\n",
    "    current_pct = current_count / len(df_oversampled)\n",
    "    \n",
    "    if current_pct < target_pct:\n",
    "        # Calculate based on the new size after previous oversampling\n",
    "        target_count = int(len(df_oversampled) * target_pct)\n",
    "        additional_samples = target_count - current_count\n",
    "        \n",
    "        # Oversample with replacement\n",
    "        group_data = df_oversampled[df_oversampled['Education_Level'] == group]\n",
    "        oversampled = group_data.sample(n=additional_samples, replace=True, random_state=42)\n",
    "        df_oversampled = pd.concat([df_oversampled, oversampled], ignore_index=True)\n",
    "        \n",
    "        print(f\"Oversampled '{group}': {current_count} → {target_count} ({current_pct:.2%} → {target_pct:.2%})\")\n",
    "\n",
    "print(f\"\\nOriginal df shape: {df.shape}\")\n",
    "print(f\"Oversampled df shape: {df_oversampled.shape}\")\n",
    "\n",
    "# Verify new distributions\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"NEW DISTRIBUTIONS AFTER OVERSAMPLING\")\n",
    "print(\"=\"*50)\n",
    "print(\"\\nRace_Ethnicity Distribution:\")\n",
    "print(df_oversampled['Race_Ethnicity'].value_counts())\n",
    "print(\"\\nEducation_Level Distribution:\")\n",
    "print(df_oversampled['Education_Level'].value_counts())\n",
    "\n",
    "df_oversampled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "deb2e820",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_oversampled.copy()\n",
    "df.to_csv('Data/sampled_dataset.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01da3b79",
   "metadata": {},
   "source": [
    "## Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6c9a75ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original shape: (10492, 46)\n",
      "Encoded shape: (10492, 55)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>General_hearing_condition</th>\n",
       "      <th>Had_high_blood_pressure</th>\n",
       "      <th>WBC</th>\n",
       "      <th>Haemoglobin</th>\n",
       "      <th>Platelete</th>\n",
       "      <th>Age</th>\n",
       "      <th>Education_Level</th>\n",
       "      <th>Household_Size</th>\n",
       "      <th>Income_to_Poverty_Ratio</th>\n",
       "      <th>Has_diabetes</th>\n",
       "      <th>...</th>\n",
       "      <th>Race_Ethnicity_Other Hispanic</th>\n",
       "      <th>Race_Ethnicity_Other Race - Including Multi-Racial</th>\n",
       "      <th>Gender_Female</th>\n",
       "      <th>Gender_Male</th>\n",
       "      <th>Country_of_Birth_Born in 50 US states or Washington</th>\n",
       "      <th>Country_of_Birth_Unknown</th>\n",
       "      <th>Marital_Status_Married/Living with partner</th>\n",
       "      <th>Marital_Status_Never married</th>\n",
       "      <th>Marital_Status_Unknown</th>\n",
       "      <th>Marital_Status_Widowed/Divorced/Separated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4.7</td>\n",
       "      <td>15.7</td>\n",
       "      <td>259.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.00</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>6.3</td>\n",
       "      <td>15.2</td>\n",
       "      <td>221.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.00</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>5.7</td>\n",
       "      <td>13.8</td>\n",
       "      <td>235.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>2</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.41</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>6.8</td>\n",
       "      <td>13.9</td>\n",
       "      <td>264.5</td>\n",
       "      <td>43.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>6.5</td>\n",
       "      <td>14.0</td>\n",
       "      <td>241.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.00</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   General_hearing_condition  Had_high_blood_pressure  WBC  Haemoglobin  \\\n",
       "0                          5                        1  4.7         15.7   \n",
       "1                          2                        1  6.3         15.2   \n",
       "2                          2                        0  5.7         13.8   \n",
       "3                          4                        0  6.8         13.9   \n",
       "4                          4                        0  6.5         14.0   \n",
       "\n",
       "   Platelete   Age  Education_Level  Household_Size  Income_to_Poverty_Ratio  \\\n",
       "0      259.0  43.0                4             4.0                     5.00   \n",
       "1      221.0  66.0                4             2.0                     5.00   \n",
       "2      235.0  44.0                2             7.0                     1.41   \n",
       "3      264.5  43.0                1             2.0                     0.63   \n",
       "4      241.0  65.0                2             2.0                     5.00   \n",
       "\n",
       "   Has_diabetes  ...  Race_Ethnicity_Other Hispanic  \\\n",
       "0             0  ...                              0   \n",
       "1             0  ...                              0   \n",
       "2             1  ...                              1   \n",
       "3             0  ...                              0   \n",
       "4             0  ...                              0   \n",
       "\n",
       "   Race_Ethnicity_Other Race - Including Multi-Racial  Gender_Female  \\\n",
       "0                                                  1               0   \n",
       "1                                                  0               0   \n",
       "2                                                  0               1   \n",
       "3                                                  0               0   \n",
       "4                                                  0               1   \n",
       "\n",
       "   Gender_Male  Country_of_Birth_Born in 50 US states or Washington  \\\n",
       "0            1                                                  0     \n",
       "1            1                                                  1     \n",
       "2            0                                                  0     \n",
       "3            1                                                  0     \n",
       "4            0                                                  1     \n",
       "\n",
       "   Country_of_Birth_Unknown  Marital_Status_Married/Living with partner  \\\n",
       "0                         1                                           1   \n",
       "1                         0                                           1   \n",
       "2                         1                                           1   \n",
       "3                         1                                           0   \n",
       "4                         0                                           1   \n",
       "\n",
       "   Marital_Status_Never married  Marital_Status_Unknown  \\\n",
       "0                             0                       0   \n",
       "1                             0                       0   \n",
       "2                             0                       0   \n",
       "3                             1                       0   \n",
       "4                             0                       0   \n",
       "\n",
       "   Marital_Status_Widowed/Divorced/Separated  \n",
       "0                                          0  \n",
       "1                                          0  \n",
       "2                                          0  \n",
       "3                                          0  \n",
       "4                                          0  \n",
       "\n",
       "[5 rows x 55 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "\n",
    "# Nominal categorical → One-Hot\n",
    "ohe_cols = [\n",
    "    \"Race_Ethnicity\",\n",
    "    \"Gender\",\n",
    "    \"Country_of_Birth\",\n",
    "    \"Marital_Status\"\n",
    "]\n",
    "\n",
    "# Binary categorical → map to 0/1/2 (Unknown as 2)\n",
    "binary_cols = [\n",
    "    \"Covered_by_health_insurance\",\n",
    "    # \"Had_alcohol_in_the_past\",\n",
    "    \"Has_Kidney_Failure\",\n",
    "    \"Had_high_blood_pressure\",\n",
    "    \"Takes_vitamin_supplements\",\n",
    "    \"Tested_for_HIV_Virus\",\n",
    "    \"Has_diabetes\",\n",
    "    \"Had_Asthma\",\n",
    "    \"Had_Arthritis\",\n",
    "    \"Had_heart_attack\",\n",
    "    \"Had_Thyroid\",\n",
    "    \"Had_Liver_COndition\",\n",
    "    \"Had_Cancer\",\n",
    "    \"Has_Hepatitis\",\n",
    "    \"Has_Disability\",\n",
    "    \"Received_Hepatitis_A_Vaccine\"\n",
    "]\n",
    "\n",
    "# Ordinal categorical → ordered encoding + Unknown at the end\n",
    "ordinal_cols = {\n",
    "    \"Age_Group\": [[\"0-18\", \"19-30\", \"31-45\", \"46-60\", \"61-75\", \"76+\", \"Unknown\"]],\n",
    "    \"Education_Level\": [[\"Less than 9th grade\",\n",
    "                         \"9-11th grade (Includes 12th grade with no diploma)\",\n",
    "                         \"High school graduate/GED or equivalent\",\n",
    "                         \"Some college or AA degree\",\n",
    "                         \"College graduate or above\",\n",
    "                         \"Unknown\"]],\n",
    "    \"General_health_condition\": [[\"Poor\", \"Fair\", \"Good\", \"Very good\", \"Excellent\", \"Unknown\"]],\n",
    "    \"General_hearing_condition\": [[\"Deaf\", \"A lot of trouble\", \"Moderate hearing trouble\",\n",
    "                                   \"A little trouble\", \"Good\", \"Excellent\", \"Unknown\"]],\n",
    "    \"functional_difficulty_composite\": [['Very Severe Difficulty', 'A lot of difficulty', 'No difficulty', 'Some difficulty','Unknown']],\n",
    "    \"Teeth_and_gum_health\": [[\"Poor\", \"Fair\", \"Good\", \"Very good\", \"Excellent\", \"Unknown\"]]\n",
    "}\n",
    "\n",
    "# --------------------------\n",
    "# Encoding functions\n",
    "# --------------------------\n",
    "\n",
    "def encode_dataset(df):\n",
    "    df_encoded = df.copy()\n",
    "\n",
    "    # Normalize all Unknown-like responses into \"Unknown\"\n",
    "    df_encoded = df_encoded.replace(\n",
    "        {\"Don't know\": \"Unknown\", \"Refused\": \"Unknown\", \"Not Applicable\": \"Unknown\", \"N/A\": \"Unknown\", \"Unknown/NA\": \"Unknown\"}\n",
    "    )\n",
    "\n",
    "    # Binary encoding: map Yes/No/Unknown\n",
    "    for col in binary_cols:\n",
    "        if col == \"Has_diabetes\":\n",
    "            df_encoded[col] = df_encoded[col].map({\"No\": 0, \"Yes\": 1, \"Borderline\": 2, \"Unknown\": 2})\n",
    "        elif col == \"Received_Hepatitis_A_Vaccine\":\n",
    "            df_encoded[col] = df_encoded[col].map({\"No doses\": 0, \"Yes, at least 2 doses\": 1, \"Less than 2 doses\": 1, \"Unknown\": 2, })\n",
    "        else:\n",
    "            df_encoded[col] = df_encoded[col].map({\"No\": 0, \"Yes\": 1, \"Unknown\": 2})\n",
    "\n",
    "    # Ordinal encoding\n",
    "    for col, categories in ordinal_cols.items():\n",
    "        if col in df_encoded.columns:\n",
    "            encoder = OrdinalEncoder(categories=categories, dtype=int)\n",
    "            df_encoded[col] = encoder.fit_transform(df_encoded[[col]])\n",
    "\n",
    "    # One-Hot encoding\n",
    "    df_encoded = pd.get_dummies(df_encoded, columns=[col for col in ohe_cols if col in df_encoded.columns], drop_first=False, dtype=int)\n",
    "\n",
    "    return df_encoded\n",
    "\n",
    "# --------------------------\n",
    "# Usage\n",
    "# --------------------------\n",
    "\n",
    "df_encoded = encode_dataset(df)\n",
    "\n",
    "print(\"Original shape:\", df.shape)\n",
    "print(\"Encoded shape:\", df_encoded.shape)\n",
    "df_encoded.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "35c4825a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column: General_hearing_condition\n",
      "[5 2 4 3 1 0 6]\n",
      "--------------------------------------------------\n",
      "Column: Had_high_blood_pressure\n",
      "[1 0 2]\n",
      "--------------------------------------------------\n",
      "Column: WBC\n",
      "[ 4.7   6.3   5.7   6.8   6.5   5.5   6.    8.3   5.8   9.7   9.5   5.6\n",
      "  5.4   6.6  10.    6.2   4.5   8.5   6.7   5.3  10.6   6.4   9.3   4.\n",
      "  6.45  6.9   8.    8.8   8.1  10.4   8.2  14.3   7.8   5.9   7.    8.7\n",
      "  7.7   5.   12.1   5.2   7.1   6.1   7.6  10.3  13.3  11.9  11.8   4.9\n",
      "  7.4   4.8   7.5  13.9  13.4   3.9  10.1   4.6   7.2  13.7  11.3   4.2\n",
      "  7.3  12.9   5.1  15.4   9.2  10.8  10.5   3.4  15.1   8.4   3.5  12.2\n",
      "  9.9   7.9  11.7   4.4   9.1   9.6  10.2   9.8   4.1  11.4   8.6  13.\n",
      " 12.8   9.    4.3  15.6   9.4   8.9   3.   13.2  11.2   2.7  11.1   3.8\n",
      " 13.5  12.6  10.9  17.4  10.7  11.5  17.5  12.7  11.6  12.    3.7  14.5\n",
      "  3.6   2.6   3.1  13.1   3.2   2.5   2.9   2.3  11.   12.4   2.2  14.1\n",
      " 14.   14.2  12.5  12.3   3.3   2.8  15.9  13.8   2.4  14.7  16.   15.3\n",
      " 16.7  15.2  14.8  15.   18.   14.9  13.6  15.8  15.7  18.4   2.1 ]\n",
      "--------------------------------------------------\n",
      "Column: Haemoglobin\n",
      "[15.7 15.2 13.8 13.9 14.  15.4 13.5 11.1 14.2 13.1 13.  12.9 13.4 14.7\n",
      " 15.8 13.7 14.1 14.5 13.6 11.5 13.2 14.3 14.4 14.9 11.  12.4 15.  15.3\n",
      " 16.1 10.7 12.1 16.2 17.4 16.3 14.6 12.7 16.6 10.9 12.2 15.6 12.8 14.8\n",
      " 11.6  9.8 15.1 12.6 11.2 11.3 17.2 12.5 10.8 16.  11.7 12.3 15.5 13.3\n",
      " 11.9  7.4 10.  16.4 11.8 17.  17.1 10.6 15.9 12.   9.6 16.5 10.4 10.2\n",
      " 16.9 17.5 11.4 18.1 16.8  9.4 17.3 16.7 17.6  9.3  9.9 18.2  9.1 17.7\n",
      " 10.3  8.1 10.5  6.3  9.5  9.  18.6  7.8  6.8  8.9 18.3  7.3 10.1  7.2\n",
      "  6.7  8.4  6.6  9.7  8.   8.7  8.3  9.2  8.5 17.8 17.9  8.2]\n",
      "--------------------------------------------------\n",
      "Column: Platelete\n",
      "[259.  221.  235.  264.5 241.  250.  237.  267.  130.  195.  329.  178.\n",
      " 297.  232.  248.  261.  199.  292.  189.  238.  260.  275.  288.  294.\n",
      " 205.  215.  223.  233.  328.  313.  226.  254.  217.  272.  381.  184.\n",
      " 190.  220.  171.  278.  350.  188.  343.  256.  203.  359.  197.  304.\n",
      " 274.  264.  236.  277.  289.  331.  222.  249.  379.  296.  333.  177.\n",
      " 154.  320.  317.  354.  301.  196.  266.  258.  252.  213.  310.  334.\n",
      " 230.  440.  242.  158.  156.  270.  300.  426.  312.  218.  424.  187.\n",
      " 211.  243.  269.  141.  307.  299.  380.  263.  165.  332.  162.  194.\n",
      " 198.  353.  303.  377.  308.  282.  174.  306.  234.  227.  393.  231.\n",
      " 153.  326.  290.  351.  251.  281.  172.  103.  225.  437.  179.  314.\n",
      " 244.  341.  413.  169.  228.  285.  167.  245.  327.  262.  240.  186.\n",
      " 318.  537.  175.  280.  192.  374.  293.  364.  361.  325.  315.  344.\n",
      " 239.  298.  268.  212.  291.  207.  208.  155.  352.  224.  108.  420.\n",
      " 160.  200.  210.  287.  387.  159.  185.  219.  372.  214.  410.  319.\n",
      " 181.  340.  271.  191.  358.  348.  323.  407.  302.  551.  391.  311.\n",
      " 114.  471.  209.  146.  279.  180.  400.  193.  132.  366.  321.  309.\n",
      " 347.  385.  216.  152.  202.  124.  284.  229.  247.  295.  147.  421.\n",
      " 438.  283.  265.  439.  398.  122.  449.  273.  145.  378.  316.  204.\n",
      " 138.  107.  466.  363.  144.  418.  414.  324.  106.  376.  305.  517.\n",
      " 405.  355.  173.  201.  246.  286.  345.  151.  383.  474.  335.  206.\n",
      " 183.  255.  128.  148.  164.  337.  423.  356.  382.  370.  336.  425.\n",
      " 349.  110.  404.  253.  133.   69.  149.  166.  150.  395.  429.  373.\n",
      " 444.  161.  384.  330.  392.  460.  396.  357.  509.  257.  518.  322.\n",
      " 182.  500.  389.  338.  371.  406.  137.  163.  157.  143.  409.  416.\n",
      " 369.  397.  168.  390.  346.  408.  136.  170.  432.  482.  461.  365.\n",
      " 417.  131.  411.  462.   93.  403.   91.  448.  484.  342.  447.  394.\n",
      " 368.  587.  388.  446.  375.  339.  176.  476.  135.  481.  121.  399.\n",
      " 453.  100.  576.  142.  276.  360.  434.  386.   85.   82.  491.  467.\n",
      " 635.  427.  485.  127.  470.  402.  726.  719.  140.  468.  415.  486.\n",
      " 457.  483.  599.  362.  436.  465.  556.  105.  459.   66.  505.  117.\n",
      "  97.   46.  669.  367.  516.  452.  433.  544.   63.  123.  488.  473.\n",
      " 129.  445.   71.  139.  675.  478.  450.  469.  435.  572.  567.  464.\n",
      "  78.  489.  118.  492.  431.  119.   99.  529.  475.   94.  463.  520.\n",
      "  81.  401.  120.  112.  526.  787.  430.  419.  442.  126.  560.  548.\n",
      " 109.  472.  499.   75.  538.  422.  477.   84.  536.  454.  494.  502.\n",
      " 412.  479.  527.  513.  506.   89. ]\n",
      "--------------------------------------------------\n",
      "Column: Age\n",
      "[43. 66. 44. 65. 34. 68. 27. 59. 31. 33. 74. 39. 51. 56. 67. 47. 26. 18.\n",
      " 12. 73. 80. 77.  7. 16. 61. 58. 53. 15. 19. 14. 11. 54. 17. 50. 63. 42.\n",
      " 41. 38. 57. 30. 70. 24.  6. 71. 72. 69. 28. 64. 10. 55. 22. 76. 60. 40.\n",
      " 75.  9. 29. 79. 62. 46. 32. 78. 20. 25. 36. 52. 13. 48. 37. 45.  8. 35.\n",
      " 49. 23. 21.]\n",
      "--------------------------------------------------\n",
      "Column: Education_Level\n",
      "[4 2 1 3 5 0]\n",
      "--------------------------------------------------\n",
      "Column: Household_Size\n",
      "[4. 2. 7. 3. 1. 5. 6.]\n",
      "--------------------------------------------------\n",
      "Column: Income_to_Poverty_Ratio\n",
      "[5.00000000e+00 1.41000000e+00 6.30000000e-01 1.33000000e+00\n",
      " 1.32000000e+00 8.10000000e-01 2.16000000e+00 9.30000000e-01\n",
      " 3.04000000e+00 1.10000000e+00 4.82000000e+00 4.48000000e+00\n",
      " 1.67000000e+00 9.10000000e-01 3.36000000e+00 4.42000000e+00\n",
      " 3.22000000e+00 4.37000000e+00 1.02000000e+00 3.14000000e+00\n",
      " 3.62000000e+00 5.00000000e-02 2.00000000e-02 1.10000000e-01\n",
      " 3.02000000e+00 2.00000000e-01 2.64000000e+00 3.82000000e+00\n",
      " 1.99000000e+00 2.19000000e+00 1.91000000e+00 8.80000000e-01\n",
      " 2.46000000e+00 3.42000000e+00 3.43000000e+00 1.19000000e+00\n",
      " 1.14000000e+00 6.70000000e-01 1.09000000e+00 1.03000000e+00\n",
      " 4.22000000e+00 6.50000000e-01 4.36000000e+00 3.47000000e+00\n",
      " 1.65000000e+00 2.74000000e+00 1.15000000e+00 2.33000000e+00\n",
      " 4.46000000e+00 4.40000000e-01 1.12000000e+00 4.80000000e-01\n",
      " 1.08000000e+00 2.92000000e+00 8.60000000e-01 2.11000000e+00\n",
      " 7.70000000e-01 1.13000000e+00 1.27000000e+00 1.29000000e+00\n",
      " 1.20000000e-01 3.00000000e-02 2.73000000e+00 7.90000000e-01\n",
      " 2.98000000e+00 1.52000000e+00 9.60000000e-01 2.06000000e+00\n",
      " 4.10000000e-01 3.97000000e+00 4.06000000e+00 3.44000000e+00\n",
      " 4.20000000e-01 2.43000000e+00 7.30000000e-01 2.09000000e+00\n",
      " 7.00000000e-01 1.64000000e+00 2.58000000e+00 1.46000000e+00\n",
      " 4.31000000e+00 1.23000000e+00 4.71000000e+00 1.83000000e+00\n",
      " 3.58000000e+00 8.70000000e-01 4.02000000e+00 1.57000000e+00\n",
      " 3.57000000e+00 9.20000000e-01 2.52000000e+00 5.10000000e-01\n",
      " 4.62000000e+00 7.00000000e-02 1.82000000e+00 1.94000000e+00\n",
      " 1.20000000e+00 1.79000000e+00 1.80000000e-01 1.66000000e+00\n",
      " 3.24000000e+00 2.88000000e+00 2.61000000e+00 1.72000000e+00\n",
      " 6.90000000e-01 4.08000000e+00 2.41000000e+00 2.17000000e+00\n",
      " 5.70000000e-01 4.54000000e+00 4.17000000e+00 2.31000000e+00\n",
      " 4.68000000e+00 6.10000000e-01 2.18000000e+00 1.84000000e+00\n",
      " 3.70000000e+00 3.30000000e+00 3.00000000e+00 2.85000000e+00\n",
      " 2.82000000e+00 1.01000000e+00 2.30000000e-01 3.90000000e-01\n",
      " 1.04000000e+00 8.50000000e-01 3.68000000e+00 1.97000000e+00\n",
      " 2.29000000e+00 2.69000000e+00 8.90000000e-01 3.28000000e+00\n",
      " 1.35000000e+00 1.61000000e+00 2.21000000e+00 1.37000000e+00\n",
      " 2.03000000e+00 1.40000000e+00 2.13000000e+00 3.18000000e+00\n",
      " 8.30000000e-01 1.44000000e+00 3.09000000e+00 2.87000000e+00\n",
      " 5.39760535e-79 3.88000000e+00 1.51000000e+00 1.75000000e+00\n",
      " 1.85000000e+00 2.40000000e-01 2.57000000e+00 1.26000000e+00\n",
      " 4.57000000e+00 1.81000000e+00 1.16000000e+00 3.41000000e+00\n",
      " 4.32000000e+00 3.40000000e-01 3.33000000e+00 1.62000000e+00\n",
      " 1.48000000e+00 7.50000000e-01 4.88000000e+00 1.39000000e+00\n",
      " 8.40000000e-01 1.69000000e+00 2.47000000e+00 2.26000000e+00\n",
      " 3.69000000e+00 3.45000000e+00 3.11000000e+00 6.60000000e-01\n",
      " 2.80000000e+00 1.71000000e+00 2.54000000e+00 3.55000000e+00\n",
      " 4.23000000e+00 2.25000000e+00 2.00000000e+00 4.83000000e+00\n",
      " 4.92000000e+00 9.40000000e-01 2.94000000e+00 2.20000000e+00\n",
      " 2.50000000e+00 3.07000000e+00 2.15000000e+00 4.69000000e+00\n",
      " 3.77000000e+00 1.11000000e+00 7.20000000e-01 2.81000000e+00\n",
      " 5.50000000e-01 4.00000000e-02 2.75000000e+00 3.06000000e+00\n",
      " 4.10000000e+00 2.07000000e+00 2.70000000e-01 5.80000000e-01\n",
      " 4.05000000e+00 2.34000000e+00 3.23000000e+00 4.30000000e-01\n",
      " 1.30000000e-01 7.60000000e-01 2.48000000e+00 5.20000000e-01\n",
      " 2.38000000e+00 1.22000000e+00 3.70000000e-01 2.28000000e+00\n",
      " 1.53000000e+00 4.55000000e+00 2.32000000e+00 1.80000000e+00\n",
      " 1.58000000e+00 3.29000000e+00 3.26000000e+00 2.59000000e+00\n",
      " 1.07000000e+00 3.80000000e+00 1.55000000e+00 1.05000000e+00\n",
      " 2.93000000e+00 2.62000000e+00 1.25000000e+00 2.96000000e+00\n",
      " 1.86000000e+00 1.90000000e-01 2.40000000e+00 4.49000000e+00\n",
      " 3.34000000e+00 3.60000000e+00 4.00000000e-01 1.34000000e+00\n",
      " 2.05000000e+00 1.18000000e+00 9.90000000e-01 3.40000000e+00\n",
      " 4.15000000e+00 1.30000000e+00 3.39000000e+00 4.60000000e+00\n",
      " 4.90000000e-01 3.13000000e+00 4.67000000e+00 2.71000000e+00\n",
      " 1.59000000e+00 3.27000000e+00 3.84000000e+00 8.20000000e-01\n",
      " 2.42000000e+00 4.33000000e+00 4.86000000e+00 3.80000000e-01\n",
      " 1.90000000e+00 3.91000000e+00 2.79000000e+00 4.59000000e+00\n",
      " 4.40000000e+00 4.80000000e+00 4.12000000e+00 3.17000000e+00\n",
      " 1.78000000e+00 1.89000000e+00 2.86000000e+00 4.34000000e+00\n",
      " 2.08000000e+00 2.35000000e+00 2.56000000e+00 2.50000000e-01\n",
      " 4.50000000e-01 4.56000000e+00 4.78000000e+00 9.80000000e-01\n",
      " 2.77000000e+00 2.83000000e+00 3.98000000e+00 3.76000000e+00\n",
      " 3.66000000e+00 1.28000000e+00 5.00000000e-01 4.00000000e+00\n",
      " 4.03000000e+00 7.80000000e-01 2.30000000e+00 1.06000000e+00\n",
      " 4.45000000e+00 2.84000000e+00 3.90000000e+00 3.00000000e-01\n",
      " 1.40000000e-01 1.98000000e+00 1.77000000e+00 1.74000000e+00\n",
      " 2.67000000e+00 1.42000000e+00 2.60000000e-01 1.21000000e+00\n",
      " 4.63000000e+00 7.40000000e-01 1.47000000e+00 1.00000000e-01\n",
      " 2.90000000e-01 3.30000000e-01 4.53000000e+00 1.49000000e+00\n",
      " 6.80000000e-01 4.64000000e+00 7.10000000e-01 1.43000000e+00\n",
      " 2.12000000e+00 4.04000000e+00 8.00000000e-01 4.11000000e+00\n",
      " 4.16000000e+00 3.16000000e+00 1.54000000e+00 2.66000000e+00\n",
      " 4.25000000e+00 3.73000000e+00 9.70000000e-01 3.96000000e+00\n",
      " 1.93000000e+00 2.89000000e+00 1.00000000e-02 1.92000000e+00\n",
      " 3.86000000e+00 1.00000000e+00 4.93000000e+00 6.20000000e-01\n",
      " 2.44000000e+00 3.49000000e+00 3.50000000e-01 1.60000000e+00\n",
      " 1.76000000e+00 1.17000000e+00 1.95000000e+00 3.54000000e+00\n",
      " 2.39000000e+00 3.12000000e+00 3.83000000e+00 3.08000000e+00\n",
      " 2.90000000e+00 2.51000000e+00 2.65000000e+00 3.46000000e+00\n",
      " 3.71000000e+00 3.31000000e+00 4.94000000e+00 3.32000000e+00\n",
      " 3.38000000e+00 1.38000000e+00 2.10000000e-01 4.14000000e+00\n",
      " 6.00000000e-02 2.78000000e+00 4.44000000e+00 1.96000000e+00\n",
      " 4.66000000e+00 1.70000000e+00 2.72000000e+00 2.63000000e+00\n",
      " 2.70000000e+00 5.30000000e-01 4.50000000e+00 4.60000000e-01\n",
      " 4.21000000e+00 5.60000000e-01 2.53000000e+00 3.85000000e+00\n",
      " 2.95000000e+00 3.19000000e+00 1.31000000e+00 2.01000000e+00\n",
      " 2.04000000e+00 4.70000000e-01 1.60000000e-01 4.97000000e+00\n",
      " 4.38000000e+00 1.50000000e-01 1.70000000e-01 4.51000000e+00\n",
      " 3.87000000e+00 8.00000000e-02 3.61000000e+00 1.68000000e+00\n",
      " 3.10000000e-01 3.94000000e+00 2.36000000e+00 4.19000000e+00\n",
      " 4.18000000e+00 4.73000000e+00 9.50000000e-01 4.95000000e+00\n",
      " 1.50000000e+00 3.15000000e+00 1.88000000e+00 3.67000000e+00\n",
      " 1.73000000e+00 1.87000000e+00 4.90000000e+00 4.13000000e+00\n",
      " 4.35000000e+00 4.75000000e+00 6.00000000e-01 9.00000000e-01\n",
      " 4.41000000e+00 2.68000000e+00 4.81000000e+00 3.93000000e+00\n",
      " 3.53000000e+00 4.30000000e+00 4.27000000e+00 4.01000000e+00\n",
      " 9.00000000e-02 3.52000000e+00 1.24000000e+00 2.22000000e+00\n",
      " 4.72000000e+00 3.65000000e+00 3.99000000e+00 2.23000000e+00\n",
      " 3.01000000e+00 2.37000000e+00 3.75000000e+00 2.24000000e+00\n",
      " 5.40000000e-01 3.60000000e-01 4.43000000e+00 2.10000000e+00\n",
      " 2.20000000e-01 3.56000000e+00 3.50000000e+00 2.80000000e-01\n",
      " 3.35000000e+00 4.89000000e+00 3.72000000e+00 2.02000000e+00\n",
      " 3.20000000e-01 4.61000000e+00 4.26000000e+00 4.91000000e+00\n",
      " 2.91000000e+00 2.55000000e+00 2.76000000e+00 5.90000000e-01\n",
      " 4.99000000e+00 3.25000000e+00 6.40000000e-01 3.92000000e+00\n",
      " 3.64000000e+00 4.70000000e+00 3.10000000e+00 4.29000000e+00\n",
      " 3.78000000e+00 2.27000000e+00 2.49000000e+00 1.63000000e+00\n",
      " 2.45000000e+00 3.37000000e+00 1.56000000e+00 3.74000000e+00\n",
      " 1.36000000e+00 3.03000000e+00 3.21000000e+00 2.14000000e+00\n",
      " 3.89000000e+00 4.28000000e+00 4.87000000e+00]\n",
      "--------------------------------------------------\n",
      "Column: Has_diabetes\n",
      "[0 1 2]\n",
      "--------------------------------------------------\n",
      "Column: Takes_vitamin_supplements\n",
      "[0 1]\n",
      "--------------------------------------------------\n",
      "Column: Has_Disability\n",
      "[0 1 2]\n",
      "--------------------------------------------------\n",
      "Column: HDL_mg\n",
      "[ 45.  60.  49.  54.  46.  42.  52.  39.  41.  37.  48.  68.  82.  47.\n",
      "  53.  81.  56.  43.  57.  32.  44.  64.  65.  40.  58.  80.  50.  62.\n",
      "  66.  67.  35.  94.  38.  75.  72.  84.  70.  51.  63.  59.  78.  33.\n",
      " 104.  61.  24.  79.  55.  90.  85.  36.  28.  34.  71.  87.  76.  69.\n",
      "  74. 111.  73.  23.  95.  97.  96.  83.  77.  88.  29.  93.  99.  31.\n",
      "  91.  98. 107.  26. 103.  30. 112.  92.  86.  25. 113. 123. 106. 110.\n",
      " 109. 127. 108.  27.  89. 120. 102. 101. 100. 116. 131. 115. 105. 121.\n",
      " 118. 138.  22.]\n",
      "--------------------------------------------------\n",
      "Column: Has_Hepatitis\n",
      "[0 1 2]\n",
      "--------------------------------------------------\n",
      "Column: Covered_by_health_insurance\n",
      "[1 0 2]\n",
      "--------------------------------------------------\n",
      "Column: Tested_for_HIV_Virus\n",
      "[0 1 2]\n",
      "--------------------------------------------------\n",
      "Column: General_health_condition\n",
      "[4 2 3 1 0 5]\n",
      "--------------------------------------------------\n",
      "Column: Received_Hepatitis_A_Vaccine\n",
      "[2 1 0]\n",
      "--------------------------------------------------\n",
      "Column: Family_poverty_level_index\n",
      "[5.00000000e+00 1.40000000e+00 2.38500000e+00 4.92000000e+00\n",
      " 1.45000000e+00 1.41000000e+00 1.74000000e+00 4.60000000e-01\n",
      " 9.40000000e-01 3.59000000e+00 4.00000000e+00 7.90000000e-01\n",
      " 3.65000000e+00 3.28000000e+00 2.63500000e+00 2.03000000e+00\n",
      " 8.90000000e-01 4.16000000e+00 4.42000000e+00 2.65000000e+00\n",
      " 1.02000000e+00 2.22000000e+00 6.50000000e-01 6.30000000e-01\n",
      " 9.50000000e-01 2.62000000e+00 1.39000000e+00 1.93000000e+00\n",
      " 2.45000000e+00 3.93000000e+00 1.90000000e+00 1.98000000e+00\n",
      " 1.85000000e+00 5.39760535e-79 2.16000000e+00 1.71000000e+00\n",
      " 1.60000000e-01 5.70000000e-01 1.35000000e+00 6.80000000e-01\n",
      " 7.80000000e-01 3.29000000e+00 4.77000000e+00 6.40000000e-01\n",
      " 4.53000000e+00 1.65000000e+00 1.64000000e+00 1.29000000e+00\n",
      " 1.86000000e+00 1.07000000e+00 9.20000000e-01 1.08000000e+00\n",
      " 6.00000000e-01 4.86000000e+00 4.80000000e-01 1.20000000e+00\n",
      " 1.51000000e+00 3.96000000e+00 1.81000000e+00 7.70000000e-01\n",
      " 8.20000000e-01 2.06000000e+00 2.43000000e+00 2.29000000e+00\n",
      " 9.00000000e-01 2.98000000e+00 1.52000000e+00 9.10000000e-01\n",
      " 3.62000000e+00 2.55000000e+00 1.99000000e+00 7.30000000e-01\n",
      " 1.47000000e+00 2.73000000e+00 1.91000000e+00 8.30000000e-01\n",
      " 3.97000000e+00 8.70000000e-01 1.55000000e+00 9.80000000e-01\n",
      " 3.44000000e+00 2.20000000e+00 4.82000000e+00 9.30000000e-01\n",
      " 3.13000000e+00 3.58000000e+00 3.86000000e+00 3.24000000e+00\n",
      " 1.26000000e+00 3.87000000e+00 1.00000000e+00 2.51000000e+00\n",
      " 6.70000000e-01 4.62000000e+00 7.10000000e-01 1.82000000e+00\n",
      " 1.12000000e+00 6.60000000e-01 3.54000000e+00 1.54000000e+00\n",
      " 2.83000000e+00 1.73000000e+00 1.37000000e+00 1.56000000e+00\n",
      " 6.90000000e-01 3.80000000e+00 4.47000000e+00 4.32000000e+00\n",
      " 3.03000000e+00 1.15000000e+00 3.01000000e+00 3.46000000e+00\n",
      " 3.07000000e+00 2.41000000e+00 1.11000000e+00 3.30000000e-01\n",
      " 2.00000000e+00 1.61000000e+00 2.86000000e+00 2.42000000e+00\n",
      " 1.30000000e+00 4.69000000e+00 1.83000000e+00 2.60000000e-01\n",
      " 1.77000000e+00 4.90000000e-01 2.34000000e+00 3.89000000e+00\n",
      " 3.91000000e+00 1.59000000e+00 1.32000000e+00 1.72000000e+00\n",
      " 4.12000000e+00 2.81000000e+00 4.59000000e+00 4.66000000e+00\n",
      " 2.47000000e+00 4.30000000e-01 3.98000000e+00 8.60000000e-01\n",
      " 4.87000000e+00 5.90000000e-01 2.87000000e+00 2.23000000e+00\n",
      " 1.69000000e+00 1.16000000e+00 7.50000000e-01 1.00000000e-01\n",
      " 3.41000000e+00 8.10000000e-01 2.21000000e+00 5.80000000e-01\n",
      " 6.20000000e-01 2.50000000e-01 1.94000000e+00 8.40000000e-01\n",
      " 2.63000000e+00 3.67000000e+00 4.10000000e-01 1.38000000e+00\n",
      " 1.34000000e+00 4.70000000e-01 3.33000000e+00 2.30000000e+00\n",
      " 2.61000000e+00 4.48000000e+00 2.74000000e+00 3.34000000e+00\n",
      " 1.68000000e+00 3.85000000e+00 2.40000000e+00 4.83000000e+00\n",
      " 8.80000000e-01 6.10000000e-01 2.08000000e+00 4.76000000e+00\n",
      " 1.04000000e+00 2.90000000e+00 2.95000000e+00 1.60000000e+00\n",
      " 2.60000000e+00 1.31000000e+00 1.95000000e+00 4.40000000e-01\n",
      " 1.42000000e+00 3.04000000e+00 3.17000000e+00 5.10000000e-01\n",
      " 3.60000000e+00 2.25000000e+00 4.65000000e+00 2.38000000e+00\n",
      " 1.49000000e+00 1.46000000e+00 1.05000000e+00 2.75000000e+00\n",
      " 3.20000000e+00 7.20000000e-01 2.59000000e+00 2.04000000e+00\n",
      " 3.53000000e+00 2.10000000e+00 3.79000000e+00 1.23000000e+00\n",
      " 3.16000000e+00 4.34000000e+00 1.09000000e+00 1.48000000e+00\n",
      " 1.28000000e+00 3.09000000e+00 1.75000000e+00 2.56000000e+00\n",
      " 4.00000000e-02 3.20000000e-01 2.96000000e+00 1.10000000e+00\n",
      " 5.40000000e-01 1.97000000e+00 4.13000000e+00 3.23000000e+00\n",
      " 4.56000000e+00 3.05000000e+00 2.80000000e+00 2.39000000e+00\n",
      " 1.84000000e+00 2.05000000e+00 1.22000000e+00 3.70000000e+00\n",
      " 3.39000000e+00 1.25000000e+00 2.36000000e+00 1.50000000e-01\n",
      " 1.96000000e+00 3.15000000e+00 3.95000000e+00 2.88000000e+00\n",
      " 1.18000000e+00 5.30000000e-01 2.12000000e+00 7.40000000e-01\n",
      " 1.57000000e+00 2.17000000e+00 1.43000000e+00 1.76000000e+00\n",
      " 4.80000000e+00 2.49000000e+00 1.63000000e+00 1.13000000e+00\n",
      " 4.10000000e+00 4.26000000e+00 2.70000000e-01 4.07000000e+00\n",
      " 4.94000000e+00 2.77000000e+00 1.80000000e+00 2.94000000e+00\n",
      " 2.30000000e-01 3.47000000e+00 9.70000000e-01 3.60000000e-01\n",
      " 2.53000000e+00 1.06000000e+00 3.11000000e+00 5.20000000e-01\n",
      " 1.03000000e+00 2.19000000e+00 1.70000000e+00 9.90000000e-01\n",
      " 3.90000000e-01 4.01000000e+00 9.60000000e-01 2.01000000e+00\n",
      " 4.43000000e+00 3.70000000e-01 2.54000000e+00 4.20000000e-01\n",
      " 1.21000000e+00 4.19000000e+00 3.73000000e+00 1.66000000e+00\n",
      " 4.17000000e+00 2.69000000e+00 2.07000000e+00 1.19000000e+00\n",
      " 4.24000000e+00 3.38000000e+00 3.26000000e+00 3.10000000e-01\n",
      " 1.20000000e-01 3.36000000e+00 4.78000000e+00 2.64000000e+00\n",
      " 2.66000000e+00 4.50000000e-01 1.80000000e-01 3.00000000e+00\n",
      " 3.51000000e+00 1.44000000e+00 1.78000000e+00 2.13000000e+00\n",
      " 3.10000000e+00 5.50000000e-01 3.83000000e+00 3.08000000e+00\n",
      " 1.89000000e+00 9.00000000e-02 4.20000000e+00 3.19000000e+00\n",
      " 1.24000000e+00 4.35000000e+00 7.00000000e-01 8.00000000e-01\n",
      " 1.58000000e+00 2.33000000e+00 2.09000000e+00 1.53000000e+00\n",
      " 2.27000000e+00 3.50000000e-01 2.71000000e+00 8.50000000e-01\n",
      " 5.60000000e-01 2.24000000e+00 4.44000000e+00 3.52000000e+00\n",
      " 2.40000000e-01 1.90000000e-01 3.74000000e+00 3.27000000e+00\n",
      " 2.48000000e+00 2.11000000e+00 3.55000000e+00 1.01000000e+00\n",
      " 4.00000000e-01 1.50000000e+00 2.31000000e+00 2.37000000e+00\n",
      " 4.14000000e+00 2.18000000e+00 2.91000000e+00 4.15000000e+00\n",
      " 3.71000000e+00 1.79000000e+00 1.88000000e+00 4.88000000e+00\n",
      " 1.33000000e+00 1.10000000e-01 2.68000000e+00 4.37000000e+00\n",
      " 4.51000000e+00 7.60000000e-01 2.97000000e+00 2.85000000e+00\n",
      " 2.32000000e+00 4.08000000e+00 4.09000000e+00 1.67000000e+00\n",
      " 3.00000000e-02 3.40000000e-01 4.64000000e+00 3.14000000e+00\n",
      " 1.30000000e-01 4.11000000e+00 3.50000000e+00 1.17000000e+00\n",
      " 2.14000000e+00 1.36000000e+00 1.62000000e+00 2.28000000e+00\n",
      " 2.92000000e+00 3.22000000e+00 2.76000000e+00 2.89000000e+00\n",
      " 3.21000000e+00 3.31000000e+00 3.00000000e-01 3.72000000e+00\n",
      " 2.02000000e+00 4.68000000e+00 2.72000000e+00 2.20000000e-01\n",
      " 7.00000000e-02 3.77000000e+00 4.04000000e+00 3.57000000e+00\n",
      " 3.35000000e+00 4.36000000e+00 4.84000000e+00 3.92000000e+00\n",
      " 4.31000000e+00 3.68000000e+00 1.14000000e+00 3.75000000e+00\n",
      " 4.61000000e+00 2.10000000e-01 5.00000000e-01 2.46000000e+00\n",
      " 1.27000000e+00 4.70000000e+00 2.82000000e+00 4.25000000e+00\n",
      " 1.70000000e-01 1.92000000e+00 3.18000000e+00 2.78000000e+00\n",
      " 2.57000000e+00 4.75000000e+00 3.99000000e+00 4.50000000e+00\n",
      " 2.00000000e-01 3.40000000e+00 4.06000000e+00 4.72000000e+00\n",
      " 3.48000000e+00 3.06000000e+00 1.87000000e+00 2.58000000e+00\n",
      " 4.02000000e+00 4.39000000e+00 3.37000000e+00 3.82000000e+00\n",
      " 4.40000000e+00 3.63000000e+00 2.70000000e+00 4.21000000e+00\n",
      " 4.03000000e+00 2.52000000e+00 4.93000000e+00 5.00000000e-02\n",
      " 3.43000000e+00 3.76000000e+00 2.79000000e+00 3.32000000e+00\n",
      " 4.28000000e+00 4.38000000e+00 2.50000000e+00]\n",
      "--------------------------------------------------\n",
      "Column: Has_Kidney_Failure\n",
      "[0 2 1]\n",
      "--------------------------------------------------\n",
      "Column: Had_Asthma\n",
      "[0 1 2]\n",
      "--------------------------------------------------\n",
      "Column: Had_Arthritis\n",
      "[1 0 2]\n",
      "--------------------------------------------------\n",
      "Column: Had_heart_attack\n",
      "[0 2 1]\n",
      "--------------------------------------------------\n",
      "Column: Had_Thyroid\n",
      "[0 1 2]\n",
      "--------------------------------------------------\n",
      "Column: Had_Liver_COndition\n",
      "[0 2 1]\n",
      "--------------------------------------------------\n",
      "Column: Had_Cancer\n",
      "[0 1 2]\n",
      "--------------------------------------------------\n",
      "Column: Teeth_and_gum_health\n",
      "[4 3 1 0 2 5]\n",
      "--------------------------------------------------\n",
      "Column: Number_of_Moderate_Physical_activities_per_week\n",
      "[ 3.00000000e+00  4.00000000e+00  1.00000000e+00  5.39760535e-79\n",
      "  5.00000000e+00  7.00000000e+00  6.00000000e+00 -1.00000000e+00\n",
      "  2.00000000e+00  1.50000000e+01  2.00000000e+01  1.00000000e+01\n",
      "  8.00000000e+00  1.80000000e+02  1.40000000e+01  3.00000000e+01\n",
      "  2.40000000e+01  1.20000000e+01  2.20000000e+01  1.04000000e+02\n",
      "  4.00000000e+01  2.80000000e+01  2.50000000e+01  2.90000000e+01\n",
      "  2.10000000e+01  5.00000000e+01]\n",
      "--------------------------------------------------\n",
      "Column: Number_of_Vigorous_Physical_activities_per_week\n",
      "[ 3.00000000e+00  5.39760535e-79  1.00000000e+00  2.00000000e+00\n",
      "  4.00000000e+00 -1.00000000e+00  5.00000000e+00  7.00000000e+00\n",
      "  6.00000000e+00  1.00000000e+01  2.00000000e+02  1.50000000e+01\n",
      "  9.00000000e+00  2.00000000e+01  3.00000000e+01  1.20000000e+01\n",
      "  8.00000000e+00  2.40000000e+01  2.20000000e+01  9.00000000e+01\n",
      "  8.40000000e+01  3.10000000e+01  2.30000000e+01]\n",
      "--------------------------------------------------\n",
      "Column: Number_of_hours_of_sleep\n",
      "[ 9.5  9.   8.   7.5  3.   7.   8.5  5.5 10.  14.  11.   6.5  6.   5.\n",
      "  3.5  4.5  4.  12.  10.5  2.  11.5 12.5 13.  13.5]\n",
      "--------------------------------------------------\n",
      "Column: Cholestrol_level\n",
      "[264. 214. 187. 186. 188. 183. 203. 167. 195. 159. 157. 191. 179. 189.\n",
      " 193. 173. 135. 174. 141. 231. 169. 163. 152. 217. 155. 166. 219. 165.\n",
      " 162. 125. 123. 161. 154. 116. 129. 194. 168. 192. 151. 148. 177. 205.\n",
      " 143. 198. 196.  84. 200. 171. 216. 234. 197. 120. 178. 172. 175. 133.\n",
      " 164. 204. 134. 146. 136. 210. 145. 144. 237. 160. 239. 103. 170. 113.\n",
      " 229. 251. 130. 199. 201. 207. 153. 225. 107. 232. 108. 142. 126. 215.\n",
      " 184. 211. 137. 156. 176. 218. 291. 150. 147. 224. 244. 106. 240. 102.\n",
      " 140. 208. 331. 190. 246. 180. 132. 158. 228. 293. 131. 124. 223. 185.\n",
      " 233. 119. 235. 222. 227. 269. 325. 284. 254. 111. 226. 128.  88. 341.\n",
      " 139. 249. 209. 276. 267. 243. 202. 101.  93. 206. 127. 268. 230. 220.\n",
      " 260. 255. 250. 212. 238. 262. 306. 213. 310. 181. 258. 149. 281. 138.\n",
      " 118. 257. 121.  99.  90. 261. 280. 105. 272. 248. 221. 117. 318. 242.\n",
      " 100. 245. 259. 241. 253. 265. 256. 122. 236. 311. 285.  94. 252. 112.\n",
      " 115. 247. 277. 294. 182. 273. 104. 287.  95. 110. 109. 327. 274. 301.\n",
      " 114. 270. 275. 271. 263. 324. 321. 292. 391.  89. 319.  86.  98.  87.\n",
      " 316. 304. 298. 361.  74. 345.  91. 296. 364. 266. 389. 302. 362. 335.\n",
      " 300. 313. 376. 344. 289. 342. 438. 393.  62. 334. 312. 283. 338.  97.\n",
      " 290. 303. 282. 315. 333. 328. 398. 314. 405.  96.  63. 297. 279. 320.\n",
      " 305.  85. 308. 326. 349.  81. 286. 278. 288. 355. 317.  80.]\n",
      "--------------------------------------------------\n",
      "Column: SystolicBP\n",
      "[132.66666667 117.         109.         113.66666667 125.66666667\n",
      " 115.         141.33333333 129.         133.         111.33333333\n",
      " 106.         158.33333333 136.         110.66666667 110.33333333\n",
      " 123.33333333 145.66666667 112.33333333 120.          87.33333333\n",
      " 111.         103.66666667 134.33333333 109.33333333 142.66666667\n",
      " 119.         132.         112.         135.33333333 121.33333333\n",
      "  86.33333333 116.33333333 154.         153.33333333 117.66666667\n",
      " 166.33333333 116.         137.66666667 118.33333333  97.33333333\n",
      " 102.66666667 126.         131.         106.33333333 110.\n",
      " 149.         113.         102.33333333 107.66666667 104.\n",
      " 146.66666667 127.         101.66666667 121.         126.66666667\n",
      "  96.66666667  95.         144.33333333 124.33333333 119.66666667\n",
      " 112.66666667 105.         105.66666667 115.33333333  89.66666667\n",
      " 102.         124.66666667 139.66666667 155.66666667 113.33333333\n",
      " 126.33333333 114.          98.66666667 125.         120.33333333\n",
      "  95.33333333 127.66666667 130.33333333 128.66666667  96.33333333\n",
      " 108.          94.         108.66666667 105.33333333  96.\n",
      " 136.33333333 162.66666667 131.33333333 130.66666667 129.66666667\n",
      " 122.         138.         164.66666667 153.66666667 123.\n",
      "  98.         140.         121.66666667 128.         124.\n",
      " 188.          93.         175.66666667 131.66666667 120.66666667\n",
      " 134.66666667 156.33333333 111.66666667 106.66666667 107.\n",
      " 148.33333333 114.33333333 125.33333333  98.33333333 122.66666667\n",
      " 122.33333333 117.33333333 101.         156.         103.33333333\n",
      " 109.66666667 107.33333333 128.33333333 130.         182.66666667\n",
      " 116.66666667 115.66666667 143.66666667  92.         152.33333333\n",
      "  93.66666667 104.66666667 101.33333333 170.         100.\n",
      " 137.33333333 123.66666667 104.33333333 150.         162.\n",
      " 114.66666667 140.33333333 118.          99.66666667  91.\n",
      " 132.33333333 134.         148.          97.         163.66666667\n",
      " 119.33333333 162.33333333  90.         157.66666667 197.33333333\n",
      "  86.          91.33333333 170.66666667 179.66666667  84.33333333\n",
      " 138.66666667  92.33333333 155.         135.         166.\n",
      " 127.33333333 138.33333333 137.          92.66666667  89.33333333\n",
      " 141.         100.33333333 169.         170.33333333 154.33333333\n",
      " 206.66666667 147.         150.33333333  97.66666667 169.33333333\n",
      " 159.         133.66666667 142.33333333 118.66666667 169.66666667\n",
      "  90.33333333 129.33333333 183.33333333 136.66666667  94.33333333\n",
      " 171.66666667 139.33333333 147.33333333 108.33333333  95.66666667\n",
      " 187.33333333 140.66666667  99.         142.         145.33333333\n",
      " 145.         159.33333333 141.66666667 144.         159.66666667\n",
      " 172.66666667 146.33333333  78.33333333 151.         135.66666667\n",
      " 103.          88.          94.66666667  91.66666667 161.33333333\n",
      " 100.66666667 144.66666667  99.33333333 147.66666667 182.33333333\n",
      "  88.33333333 153.         149.66666667  90.66666667 152.66666667\n",
      " 148.66666667 165.33333333 157.33333333 143.33333333 146.\n",
      "  85.66666667  87.66666667 154.66666667  87.         151.33333333\n",
      " 139.         171.33333333 143.         158.         176.33333333\n",
      " 155.33333333 149.33333333  83.         178.          84.\n",
      "  83.33333333 164.33333333 133.33333333 232.33333333 151.66666667\n",
      "  81.          76.         167.66666667 206.         184.66666667\n",
      "  93.33333333 181.         157.          88.66666667 158.66666667\n",
      " 156.66666667 171.         150.66666667 160.66666667  85.\n",
      " 199.          82.33333333  74.66666667 185.         167.\n",
      " 184.          82.          80.33333333 173.33333333  86.66666667\n",
      " 210.33333333 172.33333333  83.66666667 166.66666667  89.\n",
      " 201.33333333 177.33333333 161.66666667 175.         189.66666667\n",
      " 152.         163.33333333 168.         164.         182.\n",
      "  81.33333333 160.         191.33333333 183.66666667  76.33333333\n",
      " 168.33333333 193.         161.         178.33333333 165.\n",
      " 215.         202.33333333 180.33333333 174.66666667 167.33333333\n",
      " 185.66666667 175.33333333 163.         160.33333333 165.66666667\n",
      "  81.66666667 197.66666667 205.          71.33333333  84.66666667\n",
      " 179.33333333 178.66666667 211.          79.66666667 191.\n",
      " 172.         168.66666667 177.66666667 195.          85.33333333\n",
      " 174.33333333  82.66666667 177.         174.         207.33333333\n",
      " 192.33333333 192.         190.         186.66666667 176.\n",
      " 202.         176.66666667 200.         191.66666667]\n",
      "--------------------------------------------------\n",
      "Column: DiastolicBP\n",
      "[ 96.          78.66666667  78.33333333  74.33333333  74.\n",
      "  73.66666667  76.          99.66666667  79.33333333  74.66666667\n",
      "  72.66666667  71.33333333  93.          68.          81.\n",
      "  80.66666667  91.33333333  70.          70.33333333  60.66666667\n",
      "  68.66666667  62.          75.66666667  67.66666667  76.33333333\n",
      "  65.33333333  82.66666667  84.66666667  77.66666667  57.33333333\n",
      " 111.          87.33333333  66.          88.          61.\n",
      "  63.          59.33333333  75.33333333  60.          69.33333333\n",
      "  86.         100.          70.66666667  91.          54.\n",
      "  81.33333333  65.          64.66666667  72.33333333  59.66666667\n",
      "  61.33333333  83.          81.66666667  58.          64.33333333\n",
      "  78.          83.33333333  65.66666667  67.33333333  89.66666667\n",
      "  71.66666667  56.66666667  82.          75.          86.33333333\n",
      "  61.66666667  55.66666667  55.33333333  67.          66.66666667\n",
      "  54.66666667  84.33333333  63.66666667  86.66666667 114.33333333\n",
      "  64.          77.          77.33333333  90.          80.33333333\n",
      "  97.33333333  73.33333333  59.          76.66666667  80.\n",
      " 112.33333333  56.          72.          97.66666667  98.\n",
      "  79.          62.33333333  88.33333333  62.66666667  89.33333333\n",
      "  69.          68.33333333  60.33333333  83.66666667  66.33333333\n",
      "  92.         104.66666667  55.          50.          57.\n",
      "  53.          52.          95.          90.66666667  71.\n",
      "  69.66666667  79.66666667  82.33333333  52.33333333  87.\n",
      "  85.          94.66666667  57.66666667 117.33333333 108.33333333\n",
      "  54.33333333  73.          92.66666667  84.          58.66666667\n",
      "  93.33333333  63.33333333  85.33333333  51.66666667 113.66666667\n",
      "  89.         105.          99.33333333  49.66666667 115.33333333\n",
      "  92.33333333  53.33333333  87.66666667  56.33333333  50.66666667\n",
      " 109.          45.66666667 131.          98.66666667  51.\n",
      "  85.66666667 114.          91.66666667  88.66666667 103.66666667\n",
      "  97.          58.33333333  94.33333333  95.66666667  51.33333333\n",
      "  98.33333333 106.66666667  96.33333333  48.66666667  48.33333333\n",
      "  42.          34.         108.         102.33333333  99.\n",
      "  53.66666667  95.33333333 114.66666667  48.          94.\n",
      "  52.66666667  49.          93.66666667 117.66666667  44.66666667\n",
      "  43.33333333  49.33333333 115.          47.          90.33333333\n",
      "  45.33333333 101.33333333 102.          47.33333333  50.33333333\n",
      "  47.66666667 101.          44.33333333 139.         107.33333333\n",
      " 100.33333333  44.          43.66666667  96.66666667 103.\n",
      " 103.33333333 100.66666667 107.66666667 109.33333333 111.33333333\n",
      "  46.66666667  37.33333333 108.66666667 105.66666667  46.\n",
      " 110.66666667  41.33333333 125.66666667 106.33333333 104.\n",
      " 116.33333333 102.66666667  46.33333333  40.          38.33333333\n",
      " 101.66666667 106.          41.          42.33333333  45.\n",
      " 104.33333333  39.33333333 129.         112.66666667 110.33333333\n",
      " 115.66666667]\n",
      "--------------------------------------------------\n",
      "Column: Pulse\n",
      "[ 81.          72.          81.33333333  69.33333333  62.33333333\n",
      "  79.          82.          58.          94.33333333  96.33333333\n",
      "  60.33333333  64.33333333  79.66666667  66.          75.66666667\n",
      "  56.         109.66666667  74.          78.66666667  68.\n",
      "  87.33333333  70.          57.33333333  71.66666667  67.16666667\n",
      "  67.33333333  89.          67.66666667  70.66666667  66.66666667\n",
      "  89.66666667  71.          68.33333333  63.33333333  65.66666667\n",
      "  91.66666667  97.33333333 100.33333333  62.          73.33333333\n",
      "  83.33333333  56.33333333  70.33333333  77.66666667  86.\n",
      "  67.          80.66666667  83.          98.          69.\n",
      "  94.          80.          52.33333333  59.66666667  72.33333333\n",
      "  74.33333333  60.66666667  91.33333333 110.33333333  84.33333333\n",
      "  61.66666667 100.          75.33333333  63.66666667  93.66666667\n",
      "  85.66666667  74.66666667  89.33333333  59.          51.66666667\n",
      "  90.          86.33333333  55.66666667  56.66666667  60.\n",
      "  58.33333333  76.33333333  75.          62.66666667  65.\n",
      "  71.33333333  65.33333333  69.66666667  64.          82.33333333\n",
      "  87.66666667  49.          88.33333333  59.33333333  63.\n",
      "  49.66666667  92.          85.33333333  52.66666667  77.33333333\n",
      "  64.66666667  93.33333333  81.66666667  55.33333333  83.66666667\n",
      "  68.66666667 115.33333333  87.          77.         104.\n",
      "  76.66666667  66.33333333  88.         116.          78.\n",
      "  79.33333333  91.          73.66666667  57.          53.66666667\n",
      "  93.          73.          61.          84.          97.66666667\n",
      "  95.33333333  72.66666667  92.66666667  78.33333333  85.\n",
      "  48.33333333  54.33333333  80.33333333  76.          58.66666667\n",
      "  88.66666667  52.          53.          61.33333333  98.66666667\n",
      "  57.66666667  84.66666667  53.33333333  54.66666667 101.\n",
      "  86.66666667  51.33333333  99.         106.66666667  82.66666667\n",
      "  47.66666667  99.66666667 103.66666667  95.66666667  51.\n",
      " 101.33333333  98.33333333  50.33333333 100.66666667  50.\n",
      "  35.66666667  46.          43.         103.          54.\n",
      "  90.66666667 113.66666667 108.33333333  92.33333333  96.\n",
      "  97.          43.66666667  95.          94.66666667  55.\n",
      "  49.33333333  90.33333333  46.66666667  96.66666667 102.\n",
      " 102.66666667  99.33333333 116.66666667 119.         102.33333333\n",
      " 126.          42.         108.66666667  45.66666667  50.66666667\n",
      "  41.66666667 115.         104.66666667 116.33333333 105.\n",
      " 113.         107.66666667 103.33333333 118.66666667 107.\n",
      " 101.66666667 104.33333333 120.          47.          48.66666667\n",
      "  45.33333333 105.66666667 111.         106.33333333 110.66666667\n",
      "  44.66666667  44.         108.          39.          40.\n",
      "  44.33333333 112.         114.66666667 118.         112.66666667\n",
      " 106.          46.33333333  47.33333333 114.          48.\n",
      " 109.         129.33333333  40.33333333  43.33333333  42.66666667\n",
      " 114.33333333  42.33333333  41.         105.33333333 109.33333333\n",
      " 111.33333333 151.         117.33333333 128.66666667  34.\n",
      "  38.         133.33333333 129.        ]\n",
      "--------------------------------------------------\n",
      "Column: BODY_MEASURE_COMPOSITE\n",
      "[0.61454588 0.50897781 0.08732189 ... 0.28959017 0.46370399 0.128731  ]\n",
      "--------------------------------------------------\n",
      "Column: blood_macros\n",
      "[ 0.04706368  1.16678624 -0.12155953 ... -0.67525515  0.1362547\n",
      " -0.01259962]\n",
      "--------------------------------------------------\n",
      "Column: mean_steroid_ng_dl\n",
      "[ 0.35157869  0.06501522  0.07037329 ... -0.69130305  0.62751559\n",
      " -0.44676639]\n",
      "--------------------------------------------------\n",
      "Column: balance_symptom_score\n",
      "[0 6 3 1 5 2 4 7]\n",
      "--------------------------------------------------\n",
      "Column: balance_impact_score\n",
      "[0. 1. 3. 4. 2. 7. 5. 6.]\n",
      "--------------------------------------------------\n",
      "Column: fall_risk_score\n",
      "[  0.    3.5   3.    1.5   4.    5.   20.   19.    7.5  15.5   6.5   6.\n",
      " 365.    8.   22.   63.   14.5  16.5   7.  376.   12.   52.   23.   62.\n",
      "  11.5  53.5   8.5 375.   13.5   9.5  60.   59.   13.   10.5 368.5  16.\n",
      "  15.  373.  372.  367.5 369.5]\n",
      "--------------------------------------------------\n",
      "Column: functional_difficulty_composite\n",
      "[2 3 1 0]\n",
      "--------------------------------------------------\n",
      "Column: Age_Group\n",
      "[2 4 1 3 0 5]\n",
      "--------------------------------------------------\n",
      "Column: Race_Ethnicity_Mexican American\n",
      "[0 1]\n",
      "--------------------------------------------------\n",
      "Column: Race_Ethnicity_Non-Hispanic Black\n",
      "[0 1]\n",
      "--------------------------------------------------\n",
      "Column: Race_Ethnicity_Non-Hispanic White\n",
      "[0 1]\n",
      "--------------------------------------------------\n",
      "Column: Race_Ethnicity_Other Hispanic\n",
      "[0 1]\n",
      "--------------------------------------------------\n",
      "Column: Race_Ethnicity_Other Race - Including Multi-Racial\n",
      "[1 0]\n",
      "--------------------------------------------------\n",
      "Column: Gender_Female\n",
      "[0 1]\n",
      "--------------------------------------------------\n",
      "Column: Gender_Male\n",
      "[1 0]\n",
      "--------------------------------------------------\n",
      "Column: Country_of_Birth_Born in 50 US states or Washington\n",
      "[0 1]\n",
      "--------------------------------------------------\n",
      "Column: Country_of_Birth_Unknown\n",
      "[1 0]\n",
      "--------------------------------------------------\n",
      "Column: Marital_Status_Married/Living with partner\n",
      "[1 0]\n",
      "--------------------------------------------------\n",
      "Column: Marital_Status_Never married\n",
      "[0 1]\n",
      "--------------------------------------------------\n",
      "Column: Marital_Status_Unknown\n",
      "[0 1]\n",
      "--------------------------------------------------\n",
      "Column: Marital_Status_Widowed/Divorced/Separated\n",
      "[0 1]\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for col in df_encoded.columns:\n",
    "    print(f\"Column: {col}\")\n",
    "    print(df_encoded[col].unique())\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2df2ffa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Covered_by_health_insurance [1 0 2]\n",
      "Has_Kidney_Failure [0 2 1]\n",
      "Had_high_blood_pressure [1 0 2]\n",
      "Takes_vitamin_supplements [0 1]\n",
      "Tested_for_HIV_Virus [0 1 2]\n",
      "Has_diabetes [0 1 2]\n",
      "Had_Asthma [0 1 2]\n",
      "Had_Arthritis [1 0 2]\n",
      "Had_heart_attack [0 2 1]\n",
      "Had_Thyroid [0 1 2]\n",
      "Had_Liver_COndition [0 2 1]\n",
      "Had_Cancer [0 1 2]\n",
      "Has_Hepatitis [0 1 2]\n",
      "Has_Disability [0 1 2]\n",
      "Received_Hepatitis_A_Vaccine [2 1 0]\n",
      "Age_Group [2 4 1 3 0 5]\n",
      "Education_Level [4 2 1 3 5 0]\n",
      "General_health_condition [4 2 3 1 0 5]\n",
      "General_hearing_condition [5 2 4 3 1 0 6]\n",
      "functional_difficulty_composite [2 3 1 0]\n",
      "Teeth_and_gum_health [4 3 1 0 2 5]\n",
      "Original shape: (10492, 46)\n",
      "Encoded shape: (10492, 55)\n"
     ]
    }
   ],
   "source": [
    "# verify if encoding is sucessful\n",
    "\n",
    "for col in binary_cols:\n",
    "    if col in df_encoded.columns:\n",
    "        print(col, df_encoded[col].unique())\n",
    "\n",
    "\n",
    "for col in ordinal_cols.keys():\n",
    "    if col in df_encoded.columns:\n",
    "        print(col, df_encoded[col].unique())\n",
    "\n",
    "\n",
    "[col for col in df_encoded.columns if any(base in col for base in ohe_cols)]\n",
    "\n",
    "print(\"Original shape:\", df.shape)\n",
    "print(\"Encoded shape:\", df_encoded.shape)\n",
    "\n",
    "\n",
    "df = df_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dc4374d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['General_hearing_condition', 'Had_high_blood_pressure', 'WBC',\n",
       "       'Haemoglobin', 'Platelete', 'Age', 'Education_Level', 'Household_Size',\n",
       "       'Income_to_Poverty_Ratio', 'Has_diabetes', 'Takes_vitamin_supplements',\n",
       "       'Has_Disability', 'HDL_mg', 'Has_Hepatitis',\n",
       "       'Covered_by_health_insurance', 'Tested_for_HIV_Virus',\n",
       "       'General_health_condition', 'Received_Hepatitis_A_Vaccine',\n",
       "       'Family_poverty_level_index', 'Has_Kidney_Failure', 'Had_Asthma',\n",
       "       'Had_Arthritis', 'Had_heart_attack', 'Had_Thyroid',\n",
       "       'Had_Liver_COndition', 'Had_Cancer', 'Teeth_and_gum_health',\n",
       "       'Number_of_Moderate_Physical_activities_per_week',\n",
       "       'Number_of_Vigorous_Physical_activities_per_week',\n",
       "       'Number_of_hours_of_sleep', 'Cholestrol_level', 'SystolicBP',\n",
       "       'DiastolicBP', 'Pulse', 'BODY_MEASURE_COMPOSITE', 'blood_macros',\n",
       "       'mean_steroid_ng_dl', 'balance_symptom_score', 'balance_impact_score',\n",
       "       'fall_risk_score', 'functional_difficulty_composite', 'Age_Group',\n",
       "       'Race_Ethnicity_Mexican American', 'Race_Ethnicity_Non-Hispanic Black',\n",
       "       'Race_Ethnicity_Non-Hispanic White', 'Race_Ethnicity_Other Hispanic',\n",
       "       'Race_Ethnicity_Other Race - Including Multi-Racial', 'Gender_Female',\n",
       "       'Gender_Male', 'Country_of_Birth_Born in 50 US states or Washington',\n",
       "       'Country_of_Birth_Unknown',\n",
       "       'Marital_Status_Married/Living with partner',\n",
       "       'Marital_Status_Never married', 'Marital_Status_Unknown',\n",
       "       'Marital_Status_Widowed/Divorced/Separated'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3a412d87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Skewness of Numerical Columns ===\n",
      "Number_of_Vigorous_Physical_activities_per_week    36.440132\n",
      "fall_risk_score                                    17.915625\n",
      "Number_of_Moderate_Physical_activities_per_week    17.605238\n",
      "mean_steroid_ng_dl                                  4.424904\n",
      "blood_macros                                        2.974533\n",
      "balance_impact_score                                2.736562\n",
      "balance_symptom_score                               2.245220\n",
      "HDL_mg                                              1.330054\n",
      "WBC                                                 1.290663\n",
      "SystolicBP                                          1.005113\n",
      "Platelete                                           0.964591\n",
      "Cholestrol_level                                    0.789117\n",
      "Household_Size                                      0.726165\n",
      "Pulse                                               0.599069\n",
      "DiastolicBP                                         0.493675\n",
      "Family_poverty_level_index                          0.429074\n",
      "Income_to_Poverty_Ratio                             0.142136\n",
      "Number_of_hours_of_sleep                            0.065428\n",
      "Age                                                -0.182220\n",
      "BODY_MEASURE_COMPOSITE                             -0.351331\n",
      "Haemoglobin                                        -0.411141\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "numerical_cols = [\"Number_of_Vigorous_Physical_activities_per_week\",\"Number_of_Moderate_Physical_activities_per_week\",\n",
    "                  \"mean_steroid_ng_dl\",\"blood_macros\",\"HDL_mg\",\"WBC\",\"Platelete\",\"SystolicBP\",\"Household_Size\",\"Cholestrol_level\",\"Pulse\",\"DiastolicBP\",\"Family_poverty_level_index\",\"Income_to_Poverty_Ratio\",\n",
    "                  \"Number_of_hours_of_sleep\",\"BODY_MEASURE_COMPOSITE\",\"Age\",\"Haemoglobin\",'balance_symptom_score','balance_impact_score','fall_risk_score']\n",
    "\n",
    "# Skewness\n",
    "print(\"\\n=== Skewness of Numerical Columns ===\")\n",
    "print(df[numerical_cols].skew().sort_values(ascending=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "54c5b49c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Columns to log-transform\n",
    "# other columns above 0.5 are binary columns\n",
    "skewed_cols = [\"Number_of_Vigorous_Physical_activities_per_week\", \"Number_of_Moderate_Physical_activities_per_week\", \"mean_steroid_ng_dl\", \n",
    "                            \"blood_macros\", \"HDL_mg\", \"WBC\", \"Platelete\", \"SystolicBP\", \"Household_Size\", \"Cholestrol_level\", \"Pulse\",'balance_symptom_score','balance_impact_score','fall_risk_score']\n",
    "\n",
    "# Apply log1p safely (handles zeros)\n",
    "for col in skewed_cols:\n",
    "    if col in df.columns:\n",
    "        df[col] = np.log1p(df[col].clip(lower=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17f41440",
   "metadata": {},
   "source": [
    "## Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "429c09b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outliers detected (Z-score > 3):\n",
      "Number_of_Vigorous_Physical_activities_per_week: 30\n",
      "Number_of_Moderate_Physical_activities_per_week: 18\n",
      "mean_steroid_ng_dl: 150\n",
      "blood_macros: 262\n",
      "HDL_mg: 83\n",
      "WBC: 111\n",
      "Platelete: 106\n",
      "SystolicBP: 80\n",
      "Household_Size: 0\n",
      "Cholestrol_level: 73\n",
      "Pulse: 65\n",
      "DiastolicBP: 86\n",
      "Family_poverty_level_index: 0\n",
      "Income_to_Poverty_Ratio: 0\n",
      "Number_of_hours_of_sleep: 178\n",
      "BODY_MEASURE_COMPOSITE: 86\n",
      "Age: 0\n",
      "Haemoglobin: 118\n",
      "balance_symptom_score: 36\n",
      "balance_impact_score: 145\n",
      "fall_risk_score: 170\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Select numerical (continuous) columns\n",
    "numerical_cols = [\"Number_of_Vigorous_Physical_activities_per_week\",\"Number_of_Moderate_Physical_activities_per_week\",\n",
    "                  \"mean_steroid_ng_dl\",\"blood_macros\",\"HDL_mg\",\"WBC\",\"Platelete\",\"SystolicBP\",\"Household_Size\",\"Cholestrol_level\",\"Pulse\",\"DiastolicBP\",\"Family_poverty_level_index\",\"Income_to_Poverty_Ratio\",\n",
    "                  \"Number_of_hours_of_sleep\",\"BODY_MEASURE_COMPOSITE\",\"Age\",\"Haemoglobin\",'balance_symptom_score','balance_impact_score','fall_risk_score']\n",
    "\n",
    "# Z-Score method (check how many values > |3|)\n",
    "from scipy.stats import zscore\n",
    "outlier_report = {}\n",
    "for col in numerical_cols:\n",
    "    z_scores = zscore(df[col].dropna())\n",
    "    outliers = (abs(z_scores) > 3).sum()\n",
    "    outlier_report[col] = outliers\n",
    "\n",
    "print(\"Outliers detected (Z-score > 3):\")\n",
    "for col, count in outlier_report.items():\n",
    "    print(f\"{col}: {count}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "53407ba2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total columns to scale: 42\n",
      "  - Numerical continuous: 21\n",
      "  - Ordinal encoded: 6\n",
      "  - Binary encoded: 15\n",
      "  - One-hot encoded (NOT scaled): 13\n",
      "\n",
      "✓ RobustScaler applied successfully!\n",
      "✓ Scaled 42 features\n",
      "✓ One-hot encoded columns remain as 0/1\n"
     ]
    }
   ],
   "source": [
    "#StandardScaler assumes normal-like distribution. Outliers will still pull the mean/std strongly.\n",
    "\n",
    "# RobustScaler uses median and IQR → much better when outliers exist.\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "\n",
    "# Define ALL columns to scale (numerical + ordinal + binary)\n",
    "\n",
    "# 1. All numerical continuous columns\n",
    "numerical_cols = [\n",
    "    \"Number_of_Vigorous_Physical_activities_per_week\",\n",
    "    \"Number_of_Moderate_Physical_activities_per_week\",\n",
    "    \"mean_steroid_ng_dl\", \"blood_macros\", \"HDL_mg\", \"WBC\", \n",
    "    \"Platelete\", \"SystolicBP\", \"Household_Size\", \"Cholestrol_level\",\n",
    "    \"Pulse\", \"DiastolicBP\", \"Family_poverty_level_index\", \n",
    "    \"Income_to_Poverty_Ratio\", \"Number_of_hours_of_sleep\",\n",
    "    \"BODY_MEASURE_COMPOSITE\", \"Age\", \"Haemoglobin\",'balance_symptom_score','balance_impact_score','fall_risk_score'\n",
    "]\n",
    "\n",
    "# 2. Ordinal encoded columns (now integers in df_encoded)\n",
    "ordinal_cols_list = [\n",
    "    \"Age_Group\", \n",
    "    \"Education_Level\", \n",
    "    \"General_health_condition\",\n",
    "    \"General_hearing_condition\", \n",
    "    \"functional_difficulty_composite\",\n",
    "    \"Teeth_and_gum_health\"\n",
    "]\n",
    "\n",
    "# 3. Binary encoded columns (now 0/1/2 in df_encoded)\n",
    "binary_cols_list = [\n",
    "    \"Covered_by_health_insurance\",\n",
    "    \"Had_alcohol_in_the_past\",\n",
    "    \"Has_Kidney_Failure\",\n",
    "    \"Had_high_blood_pressure\",\n",
    "    \"Takes_vitamin_supplements\",\n",
    "    \"Tested_for_HIV_Virus\",\n",
    "    \"Has_diabetes\",\n",
    "    \"Had_Asthma\",\n",
    "    \"Had_Arthritis\",\n",
    "    \"Had_heart_attack\",\n",
    "    \"Had_Thyroid\",\n",
    "    \"Had_Liver_COndition\",\n",
    "    \"Had_Cancer\",\n",
    "    \"Has_Hepatitis\",\n",
    "    \"Has_Disability\",\n",
    "    \"Received_Hepatitis_A_Vaccine\"\n",
    "]\n",
    "\n",
    "# Combine all columns to scale\n",
    "cols_to_scale = numerical_cols + ordinal_cols_list + binary_cols_list\n",
    "\n",
    "# Filter only columns that exist in df_encoded\n",
    "cols_to_scale = [col for col in cols_to_scale if col in df_encoded.columns]\n",
    "\n",
    "print(f\"Total columns to scale: {len(cols_to_scale)}\")\n",
    "print(f\"  - Numerical continuous: {len([c for c in numerical_cols if c in df_encoded.columns])}\")\n",
    "print(f\"  - Ordinal encoded: {len([c for c in ordinal_cols_list if c in df_encoded.columns])}\")\n",
    "print(f\"  - Binary encoded: {len([c for c in binary_cols_list if c in df_encoded.columns])}\")\n",
    "\n",
    "# Identify one-hot encoded columns (will NOT be scaled)\n",
    "all_cols = set(df_encoded.columns)\n",
    "cols_to_scale_set = set(cols_to_scale)\n",
    "ohe_cols = list(all_cols - cols_to_scale_set)\n",
    "\n",
    "print(f\"  - One-hot encoded (NOT scaled): {len(ohe_cols)}\")\n",
    "\n",
    "# Apply RobustScaler\n",
    "scaler = RobustScaler()\n",
    "df_scaled = df_encoded.copy()\n",
    "df_scaled[cols_to_scale] = scaler.fit_transform(df_encoded[cols_to_scale])\n",
    "\n",
    "print(f\"\\n✓ RobustScaler applied successfully!\")\n",
    "print(f\"✓ Scaled {len(cols_to_scale)} features\")\n",
    "print(f\"✓ One-hot encoded columns remain as 0/1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ee81847",
   "metadata": {},
   "source": [
    "#### Apply Standard Scling as it works well for PCA and check what happens!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d32df3ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scaled.to_csv('Data/df_scaled.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f108eb5f",
   "metadata": {},
   "source": [
    "### Save all the models and results later for rela time inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca1d4524",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Preprocessing pipeline saved!\n",
      "  - Saved 6 ordinal encoders\n",
      "  - Saved scaler type: RobustScaler\n",
      "  - Total columns in pipeline: 55\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import joblib\n",
    "from sklearn.preprocessing import OrdinalEncoder, StandardScaler, RobustScaler\n",
    "\n",
    "def save_preprocessing_components(df_encoded, scaler):\n",
    "    \"\"\"\n",
    "    Save preprocessing components using the already fitted scaler\n",
    "    and creating encoders from the known mappings\n",
    "    \"\"\"\n",
    "    preprocessing_pipeline = {}\n",
    "    \n",
    "    # Save the already fitted scaler\n",
    "    preprocessing_pipeline['scaler'] = scaler\n",
    "    preprocessing_pipeline['cols_to_scale'] = cols_to_scale\n",
    "    \n",
    "    # Save binary mappings\n",
    "    preprocessing_pipeline['binary_mappings'] = {\n",
    "        \"Has_diabetes\": {\"No\": 0, \"Yes\": 1, \"Borderline\": 2, \"Unknown\": 2},\n",
    "        \"Received_Hepatitis_A_Vaccine\": {\"No doses\": 0, \"Yes, at least 2 doses\": 1, \n",
    "                                         \"Less than 2 doses\": 1, \"Unknown\": 2},\n",
    "        \"default\": {\"No\": 0, \"Yes\": 1, \"Unknown\": 2}\n",
    "    }\n",
    "    \n",
    "    # Create and save ordinal encoders from known categories\n",
    "    ordinal_encoders = {}\n",
    "    ordinal_mappings = {\n",
    "        \"Age_Group\": [\"0-18\", \"19-30\", \"31-45\", \"46-60\", \"61-75\", \"76+\", \"Unknown\"],\n",
    "        \"Education_Level\": [\"Less than 9th grade\",\n",
    "                           \"9-11th grade (Includes 12th grade with no diploma)\",\n",
    "                           \"High school graduate/GED or equivalent\",\n",
    "                           \"Some college or AA degree\",\n",
    "                           \"College graduate or above\",\n",
    "                           \"Unknown\"],\n",
    "        \"General_health_condition\": [\"Poor\", \"Fair\", \"Good\", \"Very good\", \"Excellent\", \"Unknown\"],\n",
    "        \"General_hearing_condition\": [\"Deaf\", \"A lot of trouble\", \"Moderate hearing trouble\",\n",
    "                                     \"A little trouble\", \"Good\", \"Excellent\", \"Unknown\"],\n",
    "        \"functional_difficulty_composite\": ['Very Severe Difficulty', 'A lot of difficulty', \n",
    "                                           'No difficulty', 'Some difficulty', 'Unknown'],\n",
    "        \"Teeth_and_gum_health\": [\"Poor\", \"Fair\", \"Good\", \"Very good\", \"Excellent\", \"Unknown\"]\n",
    "    }\n",
    "    \n",
    "    for col, categories in ordinal_mappings.items():\n",
    "        encoder = OrdinalEncoder(categories=[categories], dtype=int)\n",
    "        # Create dummy data to fit the encoder\n",
    "        dummy_data = [[cat] for cat in categories]\n",
    "        encoder.fit(dummy_data)\n",
    "        ordinal_encoders[col] = encoder\n",
    "    \n",
    "    preprocessing_pipeline['ordinal_encoders'] = ordinal_encoders\n",
    "    \n",
    "    # Save column lists\n",
    "    preprocessing_pipeline['binary_cols'] = binary_cols\n",
    "    preprocessing_pipeline['ohe_cols'] = ohe_cols\n",
    "    preprocessing_pipeline['skewed_cols'] = skewed_cols\n",
    "    preprocessing_pipeline['all_columns'] = df_encoded.columns.tolist()\n",
    "    \n",
    "    # Save one-hot encoded column names\n",
    "    ohe_column_names = [col for col in df_encoded.columns \n",
    "                        if any(base in col for base in ohe_cols)]\n",
    "    preprocessing_pipeline['ohe_column_names'] = ohe_column_names\n",
    "    \n",
    "    # Save to file\n",
    "    with open('Data/preprocessing_pipeline.pkl', 'wb') as f:\n",
    "        pickle.dump(preprocessing_pipeline, f)\n",
    "    \n",
    "    print(\"✓ Preprocessing pipeline saved!\")\n",
    "    print(f\"  - Saved {len(ordinal_encoders)} ordinal encoders\")\n",
    "    print(f\"  - Saved scaler type: {type(scaler).__name__}\")\n",
    "    print(f\"  - Total columns in pipeline: {len(df_encoded.columns)}\")\n",
    "    \n",
    "    return preprocessing_pipeline\n",
    "\n",
    "# Save your current pipeline (use df_scaled which is your final encoded and scaled data)\n",
    "pipeline = save_preprocessing_components(df_scaled, scaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b1f12bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def preprocess_new_record(new_record, pipeline_path='Data/preprocessing_pipeline.pkl'):\n",
    "    \"\"\"\n",
    "    Apply the same preprocessing to new records\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    new_record : dict or pd.DataFrame\n",
    "        New record(s) to preprocess\n",
    "    pipeline_path : str\n",
    "        Path to saved preprocessing pipeline\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    pd.DataFrame : Preprocessed record matching training data format\n",
    "    \"\"\"\n",
    "    \n",
    "    # Load pipeline\n",
    "    with open(pipeline_path, 'rb') as f:\n",
    "        pipeline = pickle.load(f)\n",
    "    \n",
    "    # Convert to DataFrame if needed\n",
    "    if isinstance(new_record, dict):\n",
    "        df_new = pd.DataFrame([new_record])\n",
    "    else:\n",
    "        df_new = new_record.copy()\n",
    "    \n",
    "    # Step 1: Normalize Unknown-like responses\n",
    "    df_new = df_new.replace({\n",
    "        \"Don't know\": \"Unknown\", \"Refused\": \"Unknown\", \n",
    "        \"Not Applicable\": \"Unknown\", \"N/A\": \"Unknown\", \n",
    "        \"Unknown/NA\": \"Unknown\"\n",
    "    })\n",
    "    \n",
    "    # Step 2: Binary encoding\n",
    "    for col in pipeline['binary_cols']:\n",
    "        if col not in df_new.columns:\n",
    "            continue\n",
    "        \n",
    "        if col == \"Has_diabetes\":\n",
    "            mapping = pipeline['binary_mappings'][\"Has_diabetes\"]\n",
    "        elif col == \"Received_Hepatitis_A_Vaccine\":\n",
    "            mapping = pipeline['binary_mappings'][\"Received_Hepatitis_A_Vaccine\"]\n",
    "        else:\n",
    "            mapping = pipeline['binary_mappings'][\"default\"]\n",
    "        \n",
    "        df_new[col] = df_new[col].map(mapping)\n",
    "    \n",
    "    # Step 3: Ordinal encoding\n",
    "    for col, encoder in pipeline['ordinal_encoders'].items():\n",
    "        if col in df_new.columns:\n",
    "            df_new[col] = encoder.transform(df_new[[col]])\n",
    "    \n",
    "    # Step 4: One-hot encoding\n",
    "    for base_col in pipeline['ohe_cols']:\n",
    "        if base_col in df_new.columns:\n",
    "            # Get dummies for this column\n",
    "            dummies = pd.get_dummies(df_new[base_col], prefix=base_col, dtype=int)\n",
    "            \n",
    "            # Add any missing columns from training\n",
    "            for train_col in pipeline['ohe_column_names']:\n",
    "                if base_col in train_col and train_col not in dummies.columns:\n",
    "                    dummies[train_col] = 0\n",
    "            \n",
    "            # Remove extra columns not in training\n",
    "            cols_to_keep = [col for col in dummies.columns \n",
    "                           if col in pipeline['ohe_column_names']]\n",
    "            dummies = dummies[cols_to_keep]\n",
    "            \n",
    "            # Add to dataframe\n",
    "            df_new = pd.concat([df_new.drop(columns=[base_col]), dummies], axis=1)\n",
    "    \n",
    "    # Step 5: Apply log transformation to skewed columns\n",
    "    for col in pipeline['skewed_cols']:\n",
    "        if col in df_new.columns:\n",
    "            df_new[col] = np.log1p(df_new[col].clip(lower=0))\n",
    "    \n",
    "    # Step 6: Ensure all columns from training exist\n",
    "    for col in pipeline['all_columns']:\n",
    "        if col not in df_new.columns:\n",
    "            df_new[col] = 0  # Add missing columns with default value\n",
    "    \n",
    "    # Step 7: Reorder columns to match training data\n",
    "    df_new = df_new[pipeline['all_columns']]\n",
    "    \n",
    "    # Step 8: Apply scaling\n",
    "    df_new[pipeline['cols_to_scale']] = pipeline['scaler'].transform(\n",
    "        df_new[pipeline['cols_to_scale']]\n",
    "    )\n",
    "    \n",
    "    return df_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f192a75a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of processed record: (1, 55)\n",
      "Matches training data shape: True\n",
      "\n",
      "First 5 processed values:\n",
      "General_hearing_condition    0.000000\n",
      "Had_high_blood_pressure      1.000000\n",
      "WBC                         -0.126195\n",
      "Haemoglobin                  0.214286\n",
      "Platelete                   -0.072534\n",
      "Name: 0, dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\vickv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but OrdinalEncoder was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\vickv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but OrdinalEncoder was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\vickv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but OrdinalEncoder was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\vickv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but OrdinalEncoder was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\vickv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but OrdinalEncoder was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\vickv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but OrdinalEncoder was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Example new patient record\n",
    "new_patient = {\n",
    "    'General_hearing_condition': 'Good',\n",
    "    'Had_high_blood_pressure': 'Yes',\n",
    "    'WBC': 6.5,\n",
    "    'Haemoglobin': 14.2,\n",
    "    'Platelete': 250,\n",
    "    'Gender': 'Female',\n",
    "    'Age': 45,\n",
    "    'Race_Ethnicity': 'Non-Hispanic White',\n",
    "    'Country_of_Birth': 'Born in 50 US states or Washington',\n",
    "    'Education_Level': 'College graduate or above',\n",
    "    'Marital_Status': 'Married/Living with partner',\n",
    "    'Household_Size': 4,\n",
    "    'Income_to_Poverty_Ratio': 3.5,\n",
    "    'Has_diabetes': 'No',\n",
    "    'Takes_vitamin_supplements': 'Yes',\n",
    "    'Has_Disability': 'No',\n",
    "    'HDL_mg': 55,\n",
    "    'Has_Hepatitis': 'No',\n",
    "    'Covered_by_health_insurance': 'Yes',\n",
    "    'Tested_for_HIV_Virus': 'No',\n",
    "    'General_health_condition': 'Very good',\n",
    "    'Received_Hepatitis_A_Vaccine': 'No doses',\n",
    "    'Family_poverty_level_index': 3.5,\n",
    "    'Has_Kidney_Failure': 'No',\n",
    "    'Had_Asthma': 'No',\n",
    "    'Had_Arthritis': 'No',\n",
    "    'Had_heart_attack': 'No',\n",
    "    'Had_Thyroid': 'No',\n",
    "    'Had_Liver_COndition': 'No',\n",
    "    'Had_Cancer': 'No',\n",
    "    'Teeth_and_gum_health': 'Good',\n",
    "    'Number_of_Moderate_Physical_activities_per_week': 3,\n",
    "    'Number_of_Vigorous_Physical_activities_per_week': 2,\n",
    "    'Number_of_hours_of_sleep': 7,\n",
    "    'Cholestrol_level': 180,\n",
    "    'SystolicBP': 120,\n",
    "    'DiastolicBP': 80,\n",
    "    'Pulse': 72,\n",
    "    'BODY_MEASURE_COMPOSITE': 0.5,\n",
    "    'blood_macros': 0.2,\n",
    "    'mean_steroid_ng_dl': 0.3,\n",
    "    'balance_symptom_score': 0,\n",
    "    'balance_impact_score': 0,\n",
    "    'fall_risk_score': 0,\n",
    "    'functional_difficulty_composite': 'No difficulty',\n",
    "    'Age_Group': '31-45'\n",
    "}\n",
    "\n",
    "# Preprocess the new record\n",
    "processed_patient = preprocess_new_record(new_patient)\n",
    "\n",
    "print(f\"Shape of processed record: {processed_patient.shape}\")\n",
    "print(f\"Matches training data shape: {processed_patient.shape[1] == df_scaled.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "166ad37e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>General_hearing_condition</th>\n",
       "      <th>Had_high_blood_pressure</th>\n",
       "      <th>WBC</th>\n",
       "      <th>Haemoglobin</th>\n",
       "      <th>Platelete</th>\n",
       "      <th>Age</th>\n",
       "      <th>Education_Level</th>\n",
       "      <th>Household_Size</th>\n",
       "      <th>Income_to_Poverty_Ratio</th>\n",
       "      <th>Has_diabetes</th>\n",
       "      <th>...</th>\n",
       "      <th>Race_Ethnicity_Other Hispanic</th>\n",
       "      <th>Race_Ethnicity_Other Race - Including Multi-Racial</th>\n",
       "      <th>Gender_Female</th>\n",
       "      <th>Gender_Male</th>\n",
       "      <th>Country_of_Birth_Born in 50 US states or Washington</th>\n",
       "      <th>Country_of_Birth_Unknown</th>\n",
       "      <th>Marital_Status_Married/Living with partner</th>\n",
       "      <th>Marital_Status_Never married</th>\n",
       "      <th>Marital_Status_Unknown</th>\n",
       "      <th>Marital_Status_Widowed/Divorced/Separated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.126195</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>-0.072534</td>\n",
       "      <td>-0.075</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.436829</td>\n",
       "      <td>0.340996</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   General_hearing_condition  Had_high_blood_pressure       WBC  Haemoglobin  \\\n",
       "0                        0.0                      1.0 -0.126195     0.214286   \n",
       "\n",
       "   Platelete    Age  Education_Level  Household_Size  Income_to_Poverty_Ratio  \\\n",
       "0  -0.072534 -0.075              0.5        0.436829                 0.340996   \n",
       "\n",
       "   Has_diabetes  ...  Race_Ethnicity_Other Hispanic  \\\n",
       "0           0.0  ...                              0   \n",
       "\n",
       "   Race_Ethnicity_Other Race - Including Multi-Racial  Gender_Female  \\\n",
       "0                                                  0               0   \n",
       "\n",
       "   Gender_Male  Country_of_Birth_Born in 50 US states or Washington  \\\n",
       "0            0                                                  0     \n",
       "\n",
       "   Country_of_Birth_Unknown  Marital_Status_Married/Living with partner  \\\n",
       "0                         0                                           0   \n",
       "\n",
       "   Marital_Status_Never married  Marital_Status_Unknown  \\\n",
       "0                             0                       0   \n",
       "\n",
       "   Marital_Status_Widowed/Divorced/Separated  \n",
       "0                                          0  \n",
       "\n",
       "[1 rows x 55 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_patient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a9e5ac4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the preprocessed patient data to a file (after preprocessing in the first notebook)\n",
    "# Add this at the end of your preprocessing notebook:\n",
    "processed_patient.to_csv('Data/processed_new_patient.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2de1362",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a27c158",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
