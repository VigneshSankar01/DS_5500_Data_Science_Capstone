{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9cf92f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "def preprocess_new_record(new_record, pipeline_path='Data/preprocessing_pipeline.pkl'):\n",
    "    \"\"\"\n",
    "    Apply the same preprocessing to new records\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    new_record : dict or pd.DataFrame\n",
    "        New record(s) to preprocess\n",
    "    pipeline_path : str\n",
    "        Path to saved preprocessing pipeline\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    pd.DataFrame : Preprocessed record matching training data format\n",
    "    \"\"\"\n",
    "    \n",
    "    # Load pipeline\n",
    "    with open(pipeline_path, 'rb') as f:\n",
    "        pipeline = pickle.load(f)\n",
    "    \n",
    "    # Convert to DataFrame if needed\n",
    "    if isinstance(new_record, dict):\n",
    "        df_new = pd.DataFrame([new_record])\n",
    "    else:\n",
    "        df_new = new_record.copy()\n",
    "    \n",
    "    # Step 1: Normalize Unknown-like responses\n",
    "    df_new = df_new.replace({\n",
    "        \"Don't know\": \"Unknown\", \"Refused\": \"Unknown\", \n",
    "        \"Not Applicable\": \"Unknown\", \"N/A\": \"Unknown\", \n",
    "        \"Unknown/NA\": \"Unknown\"\n",
    "    })\n",
    "    \n",
    "    # Step 2: Binary encoding\n",
    "    for col in pipeline['binary_cols']:\n",
    "        if col not in df_new.columns:\n",
    "            continue\n",
    "        \n",
    "        if col == \"Has_diabetes\":\n",
    "            mapping = pipeline['binary_mappings'][\"Has_diabetes\"]\n",
    "        elif col == \"Received_Hepatitis_A_Vaccine\":\n",
    "            mapping = pipeline['binary_mappings'][\"Received_Hepatitis_A_Vaccine\"]\n",
    "        else:\n",
    "            mapping = pipeline['binary_mappings'][\"default\"]\n",
    "        \n",
    "        df_new[col] = df_new[col].map(mapping)\n",
    "    \n",
    "    # Step 3: Ordinal encoding\n",
    "    for col, encoder in pipeline['ordinal_encoders'].items():\n",
    "        if col in df_new.columns:\n",
    "            df_new[col] = encoder.transform(df_new[[col]])\n",
    "    \n",
    "    # Step 4: One-hot encoding\n",
    "    for base_col in pipeline['ohe_cols']:\n",
    "        if base_col in df_new.columns:\n",
    "            # Get dummies for this column\n",
    "            dummies = pd.get_dummies(df_new[base_col], prefix=base_col, dtype=int)\n",
    "            \n",
    "            # Add any missing columns from training\n",
    "            for train_col in pipeline['ohe_column_names']:\n",
    "                if base_col in train_col and train_col not in dummies.columns:\n",
    "                    dummies[train_col] = 0\n",
    "            \n",
    "            # Remove extra columns not in training\n",
    "            cols_to_keep = [col for col in dummies.columns \n",
    "                           if col in pipeline['ohe_column_names']]\n",
    "            dummies = dummies[cols_to_keep]\n",
    "            \n",
    "            # Add to dataframe\n",
    "            df_new = pd.concat([df_new.drop(columns=[base_col]), dummies], axis=1)\n",
    "    \n",
    "    # Step 5: Apply log transformation to skewed columns\n",
    "    for col in pipeline['skewed_cols']:\n",
    "        if col in df_new.columns:\n",
    "            df_new[col] = np.log1p(df_new[col].clip(lower=0))\n",
    "    \n",
    "    # Step 6: Ensure all columns from training exist\n",
    "    for col in pipeline['all_columns']:\n",
    "        if col not in df_new.columns:\n",
    "            df_new[col] = 0  # Add missing columns with default value\n",
    "    \n",
    "    # Step 7: Reorder columns to match training data\n",
    "    df_new = df_new[pipeline['all_columns']]\n",
    "    \n",
    "    # Step 8: Apply scaling\n",
    "    df_new[pipeline['cols_to_scale']] = pipeline['scaler'].transform(\n",
    "        df_new[pipeline['cols_to_scale']]\n",
    "    )\n",
    "    \n",
    "    return df_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4dbbc685",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of processed record: (1050, 55)\n",
      "Matches training data shape: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\vickv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but OrdinalEncoder was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\vickv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but OrdinalEncoder was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\vickv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but OrdinalEncoder was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\vickv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but OrdinalEncoder was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\vickv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but OrdinalEncoder was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\vickv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but OrdinalEncoder was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Example new patient record\n",
    "test_df = pd.read_csv('Data/test_dataset.csv')\n",
    "df_scaled = pd.read_csv('Data/df_scaled.csv')\n",
    "df_scaled.drop(columns='Unnamed: 0', inplace=True)\n",
    "\n",
    "# Preprocess the new record\n",
    "processed_patient = preprocess_new_record(test_df)\n",
    "\n",
    "print(f\"Shape of processed record: {processed_patient.shape}\")\n",
    "print(f\"Matches training data shape: {processed_patient.shape[1] == df_scaled.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4a70483f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>General_hearing_condition</th>\n",
       "      <th>Had_high_blood_pressure</th>\n",
       "      <th>WBC</th>\n",
       "      <th>Haemoglobin</th>\n",
       "      <th>Platelete</th>\n",
       "      <th>Age</th>\n",
       "      <th>Education_Level</th>\n",
       "      <th>Household_Size</th>\n",
       "      <th>Income_to_Poverty_Ratio</th>\n",
       "      <th>Has_diabetes</th>\n",
       "      <th>...</th>\n",
       "      <th>Race_Ethnicity_Other Hispanic</th>\n",
       "      <th>Race_Ethnicity_Other Race - Including Multi-Racial</th>\n",
       "      <th>Gender_Female</th>\n",
       "      <th>Gender_Male</th>\n",
       "      <th>Country_of_Birth_Born in 50 US states or Washington</th>\n",
       "      <th>Country_of_Birth_Unknown</th>\n",
       "      <th>Marital_Status_Married/Living with partner</th>\n",
       "      <th>Marital_Status_Never married</th>\n",
       "      <th>Marital_Status_Unknown</th>\n",
       "      <th>Marital_Status_Widowed/Divorced/Separated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.126195</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>-0.206814</td>\n",
       "      <td>0.575</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>-1.356915</td>\n",
       "      <td>-0.571698</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.061874</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.133994</td>\n",
       "      <td>-0.400</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>1.095512</td>\n",
       "      <td>-0.752830</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.126195</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>-0.206814</td>\n",
       "      <td>0.425</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>-1.356915</td>\n",
       "      <td>-0.209434</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.126195</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>-0.206814</td>\n",
       "      <td>0.650</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.563171</td>\n",
       "      <td>-0.511321</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.395017</td>\n",
       "      <td>-0.714286</td>\n",
       "      <td>1.991652</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.095512</td>\n",
       "      <td>-0.481132</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9437</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.245940</td>\n",
       "      <td>-0.785714</td>\n",
       "      <td>0.809071</td>\n",
       "      <td>0.725</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>-1.356915</td>\n",
       "      <td>-0.458491</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9438</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.301680</td>\n",
       "      <td>-1.071429</td>\n",
       "      <td>0.595486</td>\n",
       "      <td>-0.800</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.436829</td>\n",
       "      <td>0.711321</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9439</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.158270</td>\n",
       "      <td>-0.357143</td>\n",
       "      <td>-0.491044</td>\n",
       "      <td>0.775</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.730189</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9440</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.530063</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.458580</td>\n",
       "      <td>0.325</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.152830</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9441</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.791047</td>\n",
       "      <td>-0.142857</td>\n",
       "      <td>-0.507497</td>\n",
       "      <td>0.350</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>-0.563171</td>\n",
       "      <td>0.688679</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9442 rows × 55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      General_hearing_condition  Had_high_blood_pressure       WBC  \\\n",
       "0                           0.0                      1.0 -0.126195   \n",
       "1                           0.0                      0.0  0.061874   \n",
       "2                           0.0                      1.0 -0.126195   \n",
       "3                          -1.0                      1.0 -0.126195   \n",
       "4                           0.0                      2.0  1.395017   \n",
       "...                         ...                      ...       ...   \n",
       "9437                        1.0                      1.0  2.245940   \n",
       "9438                       -1.0                      2.0  0.301680   \n",
       "9439                        0.0                      1.0 -0.158270   \n",
       "9440                        0.0                      0.0  0.530063   \n",
       "9441                        0.0                      0.0 -1.791047   \n",
       "\n",
       "      Haemoglobin  Platelete    Age  Education_Level  Household_Size  \\\n",
       "0        0.071429  -0.206814  0.575             -0.5       -1.356915   \n",
       "1        0.000000   0.133994 -0.400             -0.5        1.095512   \n",
       "2        0.071429  -0.206814  0.425             -0.5       -1.356915   \n",
       "3        0.071429  -0.206814  0.650              0.0       -0.563171   \n",
       "4       -0.714286   1.991652 -1.000              1.0        1.095512   \n",
       "...           ...        ...    ...              ...             ...   \n",
       "9437    -0.785714   0.809071  0.725             -0.5       -1.356915   \n",
       "9438    -1.071429   0.595486 -0.800              1.0        0.436829   \n",
       "9439    -0.357143  -0.491044  0.775             -0.5        0.000000   \n",
       "9440     0.571429   0.458580  0.325              0.0        0.000000   \n",
       "9441    -0.142857  -0.507497  0.350             -0.5       -0.563171   \n",
       "\n",
       "      Income_to_Poverty_Ratio  Has_diabetes  ...  \\\n",
       "0                   -0.571698           0.0  ...   \n",
       "1                   -0.752830           0.0  ...   \n",
       "2                   -0.209434           0.0  ...   \n",
       "3                   -0.511321           0.0  ...   \n",
       "4                   -0.481132           0.0  ...   \n",
       "...                       ...           ...  ...   \n",
       "9437                -0.458491           1.0  ...   \n",
       "9438                 0.711321           0.0  ...   \n",
       "9439                -0.730189           0.0  ...   \n",
       "9440                 0.152830           0.0  ...   \n",
       "9441                 0.688679           0.0  ...   \n",
       "\n",
       "      Race_Ethnicity_Other Hispanic  \\\n",
       "0                                 0   \n",
       "1                                 0   \n",
       "2                                 0   \n",
       "3                                 0   \n",
       "4                                 0   \n",
       "...                             ...   \n",
       "9437                              0   \n",
       "9438                              0   \n",
       "9439                              0   \n",
       "9440                              0   \n",
       "9441                              0   \n",
       "\n",
       "      Race_Ethnicity_Other Race - Including Multi-Racial  Gender_Female  \\\n",
       "0                                                     0               1   \n",
       "1                                                     0               0   \n",
       "2                                                     0               1   \n",
       "3                                                     0               0   \n",
       "4                                                     1               0   \n",
       "...                                                 ...             ...   \n",
       "9437                                                  0               1   \n",
       "9438                                                  0               1   \n",
       "9439                                                  0               1   \n",
       "9440                                                  1               1   \n",
       "9441                                                  0               1   \n",
       "\n",
       "      Gender_Male  Country_of_Birth_Born in 50 US states or Washington  \\\n",
       "0               0                                                  1     \n",
       "1               1                                                  0     \n",
       "2               0                                                  1     \n",
       "3               1                                                  1     \n",
       "4               1                                                  1     \n",
       "...           ...                                                ...     \n",
       "9437            0                                                  1     \n",
       "9438            0                                                  1     \n",
       "9439            0                                                  1     \n",
       "9440            0                                                  1     \n",
       "9441            0                                                  1     \n",
       "\n",
       "      Country_of_Birth_Unknown  Marital_Status_Married/Living with partner  \\\n",
       "0                            0                                           0   \n",
       "1                            1                                           1   \n",
       "2                            0                                           0   \n",
       "3                            0                                           0   \n",
       "4                            0                                           0   \n",
       "...                        ...                                         ...   \n",
       "9437                         0                                           0   \n",
       "9438                         0                                           0   \n",
       "9439                         0                                           0   \n",
       "9440                         0                                           0   \n",
       "9441                         0                                           1   \n",
       "\n",
       "      Marital_Status_Never married  Marital_Status_Unknown  \\\n",
       "0                                1                       0   \n",
       "1                                0                       0   \n",
       "2                                1                       0   \n",
       "3                                0                       0   \n",
       "4                                0                       1   \n",
       "...                            ...                     ...   \n",
       "9437                             0                       0   \n",
       "9438                             0                       1   \n",
       "9439                             0                       0   \n",
       "9440                             0                       0   \n",
       "9441                             0                       0   \n",
       "\n",
       "      Marital_Status_Widowed/Divorced/Separated  \n",
       "0                                             0  \n",
       "1                                             0  \n",
       "2                                             0  \n",
       "3                                             1  \n",
       "4                                             0  \n",
       "...                                         ...  \n",
       "9437                                          1  \n",
       "9438                                          0  \n",
       "9439                                          1  \n",
       "9440                                          1  \n",
       "9441                                          0  \n",
       "\n",
       "[9442 rows x 55 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "70fae908",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>General_hearing_condition</th>\n",
       "      <th>Had_high_blood_pressure</th>\n",
       "      <th>WBC</th>\n",
       "      <th>Haemoglobin</th>\n",
       "      <th>Platelete</th>\n",
       "      <th>Age</th>\n",
       "      <th>Education_Level</th>\n",
       "      <th>Household_Size</th>\n",
       "      <th>Income_to_Poverty_Ratio</th>\n",
       "      <th>Has_diabetes</th>\n",
       "      <th>...</th>\n",
       "      <th>Race_Ethnicity_Other Hispanic</th>\n",
       "      <th>Race_Ethnicity_Other Race - Including Multi-Racial</th>\n",
       "      <th>Gender_Female</th>\n",
       "      <th>Gender_Male</th>\n",
       "      <th>Country_of_Birth_Born in 50 US states or Washington</th>\n",
       "      <th>Country_of_Birth_Unknown</th>\n",
       "      <th>Marital_Status_Married/Living with partner</th>\n",
       "      <th>Marital_Status_Never married</th>\n",
       "      <th>Marital_Status_Unknown</th>\n",
       "      <th>Marital_Status_Widowed/Divorced/Separated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.441348</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.967019</td>\n",
       "      <td>-0.750</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.096226</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.061874</td>\n",
       "      <td>-0.571429</td>\n",
       "      <td>0.368728</td>\n",
       "      <td>-1.050</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.356915</td>\n",
       "      <td>-0.454717</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.753699</td>\n",
       "      <td>-0.071429</td>\n",
       "      <td>1.021824</td>\n",
       "      <td>0.425</td>\n",
       "      <td>0.5</td>\n",
       "      <td>-1.356915</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2.266201</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>-0.834974</td>\n",
       "      <td>0.675</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>0.793745</td>\n",
       "      <td>-0.013208</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.057532</td>\n",
       "      <td>-0.428571</td>\n",
       "      <td>1.529152</td>\n",
       "      <td>-0.975</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.095512</td>\n",
       "      <td>-0.481132</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1045</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.526021</td>\n",
       "      <td>-0.571429</td>\n",
       "      <td>-1.174664</td>\n",
       "      <td>0.325</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>-0.563171</td>\n",
       "      <td>-0.654717</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1046</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.886727</td>\n",
       "      <td>-2.785714</td>\n",
       "      <td>0.933739</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.658491</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1047</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.532686</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.237332</td>\n",
       "      <td>-0.450</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.575472</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.126195</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>-0.206814</td>\n",
       "      <td>0.325</td>\n",
       "      <td>0.5</td>\n",
       "      <td>-0.563171</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1049</th>\n",
       "      <td>-2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.126195</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>-0.206814</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.356915</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1050 rows × 55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      General_hearing_condition  Had_high_blood_pressure       WBC  \\\n",
       "0                           1.0                      0.0  1.441348   \n",
       "1                           1.0                      2.0  0.061874   \n",
       "2                          -1.0                      1.0  1.753699   \n",
       "3                           0.0                      0.0 -2.266201   \n",
       "4                           0.0                      2.0  1.057532   \n",
       "...                         ...                      ...       ...   \n",
       "1045                        0.0                      0.0 -0.526021   \n",
       "1046                        0.0                      0.0 -0.886727   \n",
       "1047                        0.0                      0.0  1.532686   \n",
       "1048                        0.0                      1.0 -0.126195   \n",
       "1049                       -2.0                      1.0 -0.126195   \n",
       "\n",
       "      Haemoglobin  Platelete    Age  Education_Level  Household_Size  \\\n",
       "0        0.285714   0.967019 -0.750              0.0        0.000000   \n",
       "1       -0.571429   0.368728 -1.050              1.0        1.356915   \n",
       "2       -0.071429   1.021824  0.425              0.5       -1.356915   \n",
       "3        0.142857  -0.834974  0.675             -0.5        0.793745   \n",
       "4       -0.428571   1.529152 -0.975              1.0        1.095512   \n",
       "...           ...        ...    ...              ...             ...   \n",
       "1045    -0.571429  -1.174664  0.325             -0.5       -0.563171   \n",
       "1046    -2.785714   0.933739  0.025              0.0        0.000000   \n",
       "1047    -1.000000  -0.237332 -0.450             -0.5        0.000000   \n",
       "1048     0.071429  -0.206814  0.325              0.5       -0.563171   \n",
       "1049     0.071429  -0.206814  0.625              0.0       -1.356915   \n",
       "\n",
       "      Income_to_Poverty_Ratio  Has_diabetes  ...  \\\n",
       "0                    0.096226           0.0  ...   \n",
       "1                   -0.454717           0.0  ...   \n",
       "2                    0.900000           0.0  ...   \n",
       "3                   -0.013208           0.0  ...   \n",
       "4                   -0.481132           0.0  ...   \n",
       "...                       ...           ...  ...   \n",
       "1045                -0.654717           0.0  ...   \n",
       "1046                -0.658491           0.0  ...   \n",
       "1047                -0.575472           0.0  ...   \n",
       "1048                 0.900000           0.0  ...   \n",
       "1049                 0.900000           0.0  ...   \n",
       "\n",
       "      Race_Ethnicity_Other Hispanic  \\\n",
       "0                                 0   \n",
       "1                                 0   \n",
       "2                                 0   \n",
       "3                                 0   \n",
       "4                                 0   \n",
       "...                             ...   \n",
       "1045                              0   \n",
       "1046                              0   \n",
       "1047                              0   \n",
       "1048                              0   \n",
       "1049                              0   \n",
       "\n",
       "      Race_Ethnicity_Other Race - Including Multi-Racial  Gender_Female  \\\n",
       "0                                                     0               0   \n",
       "1                                                     0               0   \n",
       "2                                                     0               0   \n",
       "3                                                     0               0   \n",
       "4                                                     0               0   \n",
       "...                                                 ...             ...   \n",
       "1045                                                  0               0   \n",
       "1046                                                  0               0   \n",
       "1047                                                  0               0   \n",
       "1048                                                  0               0   \n",
       "1049                                                  0               0   \n",
       "\n",
       "      Gender_Male  Country_of_Birth_Born in 50 US states or Washington  \\\n",
       "0               0                                                  0     \n",
       "1               0                                                  0     \n",
       "2               0                                                  0     \n",
       "3               0                                                  0     \n",
       "4               0                                                  0     \n",
       "...           ...                                                ...     \n",
       "1045            0                                                  0     \n",
       "1046            0                                                  0     \n",
       "1047            0                                                  0     \n",
       "1048            0                                                  0     \n",
       "1049            0                                                  0     \n",
       "\n",
       "      Country_of_Birth_Unknown  Marital_Status_Married/Living with partner  \\\n",
       "0                            0                                           0   \n",
       "1                            0                                           0   \n",
       "2                            0                                           0   \n",
       "3                            0                                           0   \n",
       "4                            0                                           0   \n",
       "...                        ...                                         ...   \n",
       "1045                         0                                           0   \n",
       "1046                         0                                           0   \n",
       "1047                         0                                           0   \n",
       "1048                         0                                           0   \n",
       "1049                         0                                           0   \n",
       "\n",
       "      Marital_Status_Never married  Marital_Status_Unknown  \\\n",
       "0                                0                       0   \n",
       "1                                0                       0   \n",
       "2                                0                       0   \n",
       "3                                0                       0   \n",
       "4                                0                       0   \n",
       "...                            ...                     ...   \n",
       "1045                             0                       0   \n",
       "1046                             0                       0   \n",
       "1047                             0                       0   \n",
       "1048                             0                       0   \n",
       "1049                             0                       0   \n",
       "\n",
       "      Marital_Status_Widowed/Divorced/Separated  \n",
       "0                                             0  \n",
       "1                                             0  \n",
       "2                                             0  \n",
       "3                                             0  \n",
       "4                                             0  \n",
       "...                                         ...  \n",
       "1045                                          0  \n",
       "1046                                          0  \n",
       "1047                                          0  \n",
       "1048                                          0  \n",
       "1049                                          0  \n",
       "\n",
       "[1050 rows x 55 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_patient"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60a04dfb",
   "metadata": {},
   "source": [
    "### Apply the same scaling and encoding as the train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "81eb341a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'sklearn.decomposition._pca.PCA'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\vickv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:376: InconsistentVersionWarning: Trying to unpickle estimator PCA from version 1.3.0 when using version 1.5.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "pca_obj = joblib.load('Data/pca_model.pkl')\n",
    "print(type(pca_obj))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b608830f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PC1</th>\n",
       "      <th>PC2</th>\n",
       "      <th>PC3</th>\n",
       "      <th>PC4</th>\n",
       "      <th>PC5</th>\n",
       "      <th>PC6</th>\n",
       "      <th>PC7</th>\n",
       "      <th>PC8</th>\n",
       "      <th>PC9</th>\n",
       "      <th>PC10</th>\n",
       "      <th>PC11</th>\n",
       "      <th>PC12</th>\n",
       "      <th>PC13</th>\n",
       "      <th>PC14</th>\n",
       "      <th>PC15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.113172</td>\n",
       "      <td>-1.533393</td>\n",
       "      <td>0.758377</td>\n",
       "      <td>3.098627</td>\n",
       "      <td>0.347120</td>\n",
       "      <td>-2.097137</td>\n",
       "      <td>0.264740</td>\n",
       "      <td>1.656713</td>\n",
       "      <td>0.981266</td>\n",
       "      <td>-1.057706</td>\n",
       "      <td>0.448963</td>\n",
       "      <td>0.552467</td>\n",
       "      <td>-0.069899</td>\n",
       "      <td>0.074268</td>\n",
       "      <td>0.989813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-5.575248</td>\n",
       "      <td>2.321419</td>\n",
       "      <td>-0.286932</td>\n",
       "      <td>-0.385998</td>\n",
       "      <td>0.209792</td>\n",
       "      <td>0.111523</td>\n",
       "      <td>0.680988</td>\n",
       "      <td>0.206258</td>\n",
       "      <td>0.706181</td>\n",
       "      <td>-0.047649</td>\n",
       "      <td>-0.797970</td>\n",
       "      <td>0.577711</td>\n",
       "      <td>0.197332</td>\n",
       "      <td>0.301666</td>\n",
       "      <td>-0.512739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.076240</td>\n",
       "      <td>-1.809363</td>\n",
       "      <td>-1.359951</td>\n",
       "      <td>-1.711618</td>\n",
       "      <td>2.563668</td>\n",
       "      <td>-0.929185</td>\n",
       "      <td>-3.114504</td>\n",
       "      <td>-1.257207</td>\n",
       "      <td>0.498358</td>\n",
       "      <td>-1.350981</td>\n",
       "      <td>-0.207992</td>\n",
       "      <td>-2.046960</td>\n",
       "      <td>0.044664</td>\n",
       "      <td>-0.824568</td>\n",
       "      <td>1.680211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.553449</td>\n",
       "      <td>3.006607</td>\n",
       "      <td>0.907166</td>\n",
       "      <td>-1.245962</td>\n",
       "      <td>-1.023825</td>\n",
       "      <td>1.045297</td>\n",
       "      <td>0.585414</td>\n",
       "      <td>-0.675157</td>\n",
       "      <td>1.765589</td>\n",
       "      <td>0.710134</td>\n",
       "      <td>0.599043</td>\n",
       "      <td>0.089877</td>\n",
       "      <td>0.292051</td>\n",
       "      <td>0.815460</td>\n",
       "      <td>-0.178022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-5.434803</td>\n",
       "      <td>2.295273</td>\n",
       "      <td>0.305455</td>\n",
       "      <td>-1.150903</td>\n",
       "      <td>0.947210</td>\n",
       "      <td>-0.680308</td>\n",
       "      <td>-0.273558</td>\n",
       "      <td>-0.303020</td>\n",
       "      <td>0.038937</td>\n",
       "      <td>-1.227287</td>\n",
       "      <td>-1.356188</td>\n",
       "      <td>1.057583</td>\n",
       "      <td>-0.175903</td>\n",
       "      <td>0.536208</td>\n",
       "      <td>0.407955</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        PC1       PC2       PC3       PC4       PC5       PC6       PC7  \\\n",
       "0  1.113172 -1.533393  0.758377  3.098627  0.347120 -2.097137  0.264740   \n",
       "1 -5.575248  2.321419 -0.286932 -0.385998  0.209792  0.111523  0.680988   \n",
       "2  1.076240 -1.809363 -1.359951 -1.711618  2.563668 -0.929185 -3.114504   \n",
       "3  3.553449  3.006607  0.907166 -1.245962 -1.023825  1.045297  0.585414   \n",
       "4 -5.434803  2.295273  0.305455 -1.150903  0.947210 -0.680308 -0.273558   \n",
       "\n",
       "        PC8       PC9      PC10      PC11      PC12      PC13      PC14  \\\n",
       "0  1.656713  0.981266 -1.057706  0.448963  0.552467 -0.069899  0.074268   \n",
       "1  0.206258  0.706181 -0.047649 -0.797970  0.577711  0.197332  0.301666   \n",
       "2 -1.257207  0.498358 -1.350981 -0.207992 -2.046960  0.044664 -0.824568   \n",
       "3 -0.675157  1.765589  0.710134  0.599043  0.089877  0.292051  0.815460   \n",
       "4 -0.303020  0.038937 -1.227287 -1.356188  1.057583 -0.175903  0.536208   \n",
       "\n",
       "       PC15  \n",
       "0  0.989813  \n",
       "1 -0.512739  \n",
       "2  1.680211  \n",
       "3 -0.178022  \n",
       "4  0.407955  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca = joblib.load('Data/pca_model.pkl')\n",
    "pca_test = pca.transform(processed_patient)\n",
    "pca_test_df = pd.DataFrame(pca_test, columns=[f'PC{i+1}' for i in range(pca_test.shape[1])])\n",
    "pca_test_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2d4236b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1050, 15)\n"
     ]
    }
   ],
   "source": [
    "print(pca_test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6b518e89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "LOADING CLUSTERING MODELS\n",
      "======================================================================\n",
      "✓ All models loaded successfully\n",
      "\n",
      "======================================================================\n",
      "ASSIGNING CLUSTERS TO TEST PATIENTS\n",
      "======================================================================\n",
      "Test data shape: (1050, 15)\n",
      "\n",
      "======================================================================\n",
      "CLUSTER ASSIGNMENT SUMMARY\n",
      "======================================================================\n",
      "\n",
      "Initial cluster distribution (4 clusters):\n",
      "Initial_Cluster\n",
      "0    356\n",
      "1    171\n",
      "2     97\n",
      "3    426\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Final cluster distribution (8 clusters):\n",
      "Final_Cluster\n",
      "0    356\n",
      "1    171\n",
      "2     36\n",
      "3     54\n",
      "4      7\n",
      "5    137\n",
      "6    118\n",
      "7    171\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Cluster mapping:\n",
      "  Cluster 0: Original Cluster 0 (no subclustering)\n",
      "  Cluster 1: Original Cluster 1 (no subclustering)\n",
      "  Cluster 2: Original Cluster 2 → Subcluster 0\n",
      "  Cluster 3: Original Cluster 2 → Subcluster 1\n",
      "  Cluster 4: Original Cluster 2 → Subcluster 2\n",
      "  Cluster 5: Original Cluster 3 → Subcluster 0\n",
      "  Cluster 6: Original Cluster 3 → Subcluster 1\n",
      "  Cluster 7: Original Cluster 3 → Subcluster 2\n",
      "\n",
      "First 20 patient assignments:\n",
      "    Initial_Cluster  Subcluster  Final_Cluster\n",
      "0                 3         2.0              7\n",
      "1                 1         NaN              1\n",
      "2                 0         NaN              0\n",
      "3                 2         1.0              3\n",
      "4                 1         NaN              1\n",
      "5                 3         2.0              7\n",
      "6                 2         1.0              3\n",
      "7                 3         0.0              5\n",
      "8                 1         NaN              1\n",
      "9                 2         1.0              3\n",
      "10                3         2.0              7\n",
      "11                3         0.0              5\n",
      "12                0         NaN              0\n",
      "13                3         1.0              6\n",
      "14                1         NaN              1\n",
      "15                3         2.0              7\n",
      "16                0         NaN              0\n",
      "17                0         NaN              0\n",
      "18                0         NaN              0\n",
      "19                2         1.0              3\n",
      "\n",
      "✓ Results saved to 'Data/test_patients_with_clusters.csv'\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "import pandas as pd\n",
    "\n",
    "# ============================================================\n",
    "# LOAD CLUSTERING MODELS\n",
    "# ============================================================\n",
    "print(\"=\"*70)\n",
    "print(\"LOADING CLUSTERING MODELS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Load clustering models\n",
    "kmeans_final = joblib.load('Models/kmeans_initial.pkl')\n",
    "kmeans_c2 = joblib.load('Models/kmeans_cluster0_split.pkl')  # Originally cluster 0, now splitting cluster 2\n",
    "kmeans_c3 = joblib.load('Models/kmeans_cluster3_split.pkl')\n",
    "\n",
    "k_split_c2 = 3\n",
    "k_split_c3 = 3\n",
    "\n",
    "print(\"✓ All models loaded successfully\")\n",
    "\n",
    "# ============================================================\n",
    "# ASSIGN CLUSTERS TO ALL TEST PATIENTS\n",
    "# ============================================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ASSIGNING CLUSTERS TO TEST PATIENTS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(f\"Test data shape: {pca_test_df.shape}\")\n",
    "\n",
    "# Step 1: Get initial cluster assignments (4 clusters)\n",
    "initial_clusters = kmeans_final.predict(pca_test_df)\n",
    "\n",
    "# Step 2: Apply hierarchical logic to get final clusters\n",
    "final_clusters = []\n",
    "subcluster_assignments = []\n",
    "\n",
    "for idx in range(len(pca_test_df)):\n",
    "    main_cluster = initial_clusters[idx]\n",
    "    patient_features = pca_test_df.iloc[[idx]]\n",
    "    \n",
    "    if main_cluster == 0:\n",
    "        # Cluster 0 stays as 0\n",
    "        final_clusters.append(0)\n",
    "        subcluster_assignments.append(None)\n",
    "        \n",
    "    elif main_cluster == 1:\n",
    "        # Cluster 1 stays as 1\n",
    "        final_clusters.append(1)\n",
    "        subcluster_assignments.append(None)\n",
    "        \n",
    "    elif main_cluster == 2:\n",
    "        # Original Cluster 2 splits into subclusters → Final clusters 2, 3, 4\n",
    "        subcluster_id = kmeans_c2.predict(patient_features)[0]\n",
    "        final_cluster = 2 + subcluster_id\n",
    "        final_clusters.append(final_cluster)\n",
    "        subcluster_assignments.append(subcluster_id)\n",
    "        \n",
    "    elif main_cluster == 3:\n",
    "        # Original Cluster 3 splits into subclusters → Final clusters 5, 6, 7\n",
    "        subcluster_id = kmeans_c3.predict(patient_features)[0]\n",
    "        final_cluster = 5 + subcluster_id\n",
    "        final_clusters.append(final_cluster)\n",
    "        subcluster_assignments.append(subcluster_id)\n",
    "\n",
    "# Add results to original processed_patient dataframe\n",
    "processed_patient['Initial_Cluster'] = initial_clusters\n",
    "processed_patient['Subcluster'] = subcluster_assignments\n",
    "processed_patient['Final_Cluster'] = final_clusters\n",
    "\n",
    "# ============================================================\n",
    "# DISPLAY RESULTS\n",
    "# ============================================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"CLUSTER ASSIGNMENT SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\\nInitial cluster distribution (4 clusters):\")\n",
    "print(processed_patient['Initial_Cluster'].value_counts().sort_index())\n",
    "\n",
    "print(\"\\nFinal cluster distribution (8 clusters):\")\n",
    "print(processed_patient['Final_Cluster'].value_counts().sort_index())\n",
    "\n",
    "print(\"\\nCluster mapping:\")\n",
    "print(\"  Cluster 0: Original Cluster 0 (no subclustering)\")\n",
    "print(\"  Cluster 1: Original Cluster 1 (no subclustering)\")\n",
    "print(\"  Cluster 2: Original Cluster 2 → Subcluster 0\")\n",
    "print(\"  Cluster 3: Original Cluster 2 → Subcluster 1\")\n",
    "print(\"  Cluster 4: Original Cluster 2 → Subcluster 2\")\n",
    "print(\"  Cluster 5: Original Cluster 3 → Subcluster 0\")\n",
    "print(\"  Cluster 6: Original Cluster 3 → Subcluster 1\")\n",
    "print(\"  Cluster 7: Original Cluster 3 → Subcluster 2\")\n",
    "\n",
    "# Show first 20 assignments\n",
    "print(\"\\nFirst 20 patient assignments:\")\n",
    "print(processed_patient[['Initial_Cluster', 'Subcluster', 'Final_Cluster']].head(20))\n",
    "\n",
    "# Save results\n",
    "processed_patient.to_csv('Data/test_patients_with_clusters_kmeans_pca.csv', index=False)\n",
    "print(\"\\n✓ Results saved to 'Data/test_patients_with_clusters.csv'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f325cc7",
   "metadata": {},
   "source": [
    "### Cluster Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d7dd4cd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "CLUSTER ASSIGNMENT VALIDATION\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import silhouette_score, davies_bouldin_score, calinski_harabasz_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"CLUSTER ASSIGNMENT VALIDATION\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24115939",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data loaded: (9442, 15)\n",
      "Columns: ['PC1', 'PC2', 'PC3', 'PC4', 'PC5', 'PC6', 'PC7', 'PC8', 'PC9', 'PC10', 'PC11', 'PC12', 'PC13', 'PC14', 'PC15']\n",
      "\n",
      "First few rows:\n",
      "        PC1       PC2       PC3       PC4       PC5       PC6       PC7  \\\n",
      "0  0.376799 -1.592803 -1.267176 -0.962705  0.118080  0.059719  0.418691   \n",
      "1  0.142066 -1.490613  1.106300  1.124161  0.234284  0.578801  1.394527   \n",
      "2  0.417423 -1.607544 -0.689641 -0.762268 -0.148614 -0.576068  0.265904   \n",
      "3  0.521385 -1.724803 -0.448313 -0.786287 -0.776098 -0.217052 -0.155178   \n",
      "4 -5.694743  2.437249 -0.859624  0.227490  0.507465 -0.860323  0.308745   \n",
      "\n",
      "        PC8       PC9      PC10      PC11      PC12      PC13      PC14  \\\n",
      "0 -0.939909  0.693531 -0.184363 -0.082870 -0.834715 -0.721033  0.476347   \n",
      "1 -0.376332  0.587263 -0.351328 -0.666097  1.891433  0.353181  0.004293   \n",
      "2  0.769184  1.052700 -0.938662  0.282397 -0.723400 -0.783167  0.192645   \n",
      "3 -0.073299  0.249685 -0.801238 -0.022679  0.905133 -0.796509  0.608106   \n",
      "4 -0.215365 -0.193520 -1.164396 -1.196037  1.431701  0.329029  0.720662   \n",
      "\n",
      "       PC15  \n",
      "0 -0.922737  \n",
      "1  0.782449  \n",
      "2 -0.814376  \n",
      "3 -0.279307  \n",
      "4  0.227026  \n"
     ]
    }
   ],
   "source": [
    "# Load the training PCA data\n",
    "df_pca = pd.read_csv('Data/pca_dataset.csv')\n",
    "\n",
    "print(f\"Training data loaded: {df_pca.shape}\")\n",
    "print(f\"Columns: {df_pca.columns.tolist()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "35dca2e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Metric 1] Within-Cluster Variance Stability\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Within-cluster variance comparison (Initial 4 clusters):\n",
      "Cluster    Train Variance       Test Variance        % Change       \n",
      "----------------------------------------------------------------------\n",
      "0          15.5138              14.6573              -5.52%  ✓ Stable\n",
      "1          9.9453               8.6473               -13.05%  ✓ Stable\n",
      "2          26.9636              28.2014              +4.59%  ✓ Stable\n",
      "3          13.6910              12.8781              -5.94%  ✓ Stable\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n[Metric 1] Within-Cluster Variance Stability\")\n",
    "print(\"-\"*70)\n",
    "\n",
    "def calculate_within_cluster_variance(data, labels, centroids):\n",
    "    \"\"\"Calculate within-cluster variance for each cluster\"\"\"\n",
    "    variances = {}\n",
    "    for cluster_id in np.unique(labels):\n",
    "        cluster_points = data[labels == cluster_id]\n",
    "        centroid = centroids[cluster_id]\n",
    "        variance = np.mean(np.sum((cluster_points - centroid)**2, axis=1))\n",
    "        variances[cluster_id] = variance\n",
    "    return variances\n",
    "\n",
    "# For initial 4 clusters - calculate on TRAINING data\n",
    "train_initial_labels = kmeans_final.labels_  # Training labels\n",
    "train_centroids = kmeans_final.cluster_centers_\n",
    "\n",
    "# Calculate training variance\n",
    "train_variances = calculate_within_cluster_variance(\n",
    "    df_pca.drop(columns=['Cluster', 'Cluster_Original', 'Cluster_Refined'], errors='ignore').values,\n",
    "    train_initial_labels,\n",
    "    train_centroids\n",
    ")\n",
    "\n",
    "# Calculate test variance\n",
    "test_initial_labels = initial_clusters\n",
    "# ✅ Use correct object (pca_test_df if DataFrame, else pca_test if array)\n",
    "test_data = pca_test_df.values if 'pca_test_df' in locals() else pca_test\n",
    "\n",
    "test_variances = calculate_within_cluster_variance(\n",
    "    test_data,\n",
    "    test_initial_labels,\n",
    "    train_centroids\n",
    ")\n",
    "\n",
    "print(\"\\nWithin-cluster variance comparison (Initial 4 clusters):\")\n",
    "print(f\"{'Cluster':<10} {'Train Variance':<20} {'Test Variance':<20} {'% Change':<15}\")\n",
    "print(\"-\"*70)\n",
    "\n",
    "for cluster_id in sorted(train_variances.keys()):\n",
    "    train_var = train_variances[cluster_id]\n",
    "    test_var = test_variances.get(cluster_id, np.nan)\n",
    "    \n",
    "    if not np.isnan(test_var):\n",
    "        pct_change = ((test_var - train_var) / train_var) * 100\n",
    "        status = \"✓ Stable\" if abs(pct_change) < 20 else \"⚠ Check\"\n",
    "        print(f\"{cluster_id:<10} {train_var:<20.4f} {test_var:<20.4f} {pct_change:>+.2f}%  {status}\")\n",
    "    else:\n",
    "        print(f\"{cluster_id:<10} {train_var:<20.4f} {'No test samples':<20} {'N/A':<15}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f4e2b8dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Metric 2] Within-Cluster Variance Stability (Final 8 Clusters)\n",
      "---------------------------------------------------------------------------\n",
      "✓ Computed 8 centroids in full PCA space\n",
      "  Centroid shape: (15,)\n",
      "\n",
      "Within-cluster variance comparison (Final 8 clusters):\n",
      "Cluster    Train Variance       Test Variance        % Change       \n",
      "---------------------------------------------------------------------------\n",
      "0          15.5138              14.6577              -5.52%  ✓ Stable\n",
      "1          9.9453               8.6473               -13.05%  ✓ Stable\n",
      "2          29.4211              31.8988              +8.42%  ✓ Stable\n",
      "3          21.1466              21.2464              +0.47%  ✓ Stable\n",
      "4          24.8174              29.9110              +20.52%  ✓ Stable\n",
      "5          12.6113              12.6435              +0.26%  ✓ Stable\n",
      "6          11.2515              10.2018              -9.33%  ✓ Stable\n",
      "7          10.4670              9.4696               -9.53%  ✓ Stable\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "print(\"\\n[Metric 2] Within-Cluster Variance Stability (Final 8 Clusters)\")\n",
    "print(\"-\"*75)\n",
    "\n",
    "def calculate_within_cluster_variance(data, labels, centroids):\n",
    "    \"\"\"Calculate within-cluster variance for each cluster\"\"\"\n",
    "    variances = {}\n",
    "    for cluster_id in np.unique(labels):\n",
    "        cluster_points = data[labels == cluster_id]\n",
    "        if len(cluster_points) == 0:\n",
    "            continue\n",
    "        centroid = centroids[cluster_id]\n",
    "        variance = np.mean(np.sum((cluster_points - centroid)**2, axis=1))\n",
    "        variances[cluster_id] = variance\n",
    "    return variances\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# TRAINING DATA AND LABELS\n",
    "# ============================================================\n",
    "train_pca = df_pca.drop(columns=['Cluster', 'Cluster_Original', 'Cluster_Refined'], errors='ignore').values\n",
    "train_initial_labels = kmeans_final.labels_\n",
    "\n",
    "# Map each training sample to one of the final 8 clusters\n",
    "train_final_clusters = []\n",
    "\n",
    "for idx, main_cluster in enumerate(train_initial_labels):\n",
    "    point = train_pca[idx].reshape(1, -1)\n",
    "    if main_cluster == 0:\n",
    "        train_final_clusters.append(0)\n",
    "    elif main_cluster == 1:\n",
    "        train_final_clusters.append(1)\n",
    "    elif main_cluster == 2:\n",
    "        sub_id = kmeans_c2.predict(point)[0]\n",
    "        train_final_clusters.append(2 + sub_id)\n",
    "    elif main_cluster == 3:\n",
    "        sub_id = kmeans_c3.predict(point)[0]\n",
    "        train_final_clusters.append(5 + sub_id)\n",
    "\n",
    "train_final_clusters = np.array(train_final_clusters)\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# COMPUTE ACTUAL CENTROIDS IN FULL PCA SPACE\n",
    "# ============================================================\n",
    "# Calculate the TRUE centroids by averaging points assigned to each cluster\n",
    "final_centroids = []\n",
    "\n",
    "for cluster_id in range(8):\n",
    "    cluster_points = train_pca[train_final_clusters == cluster_id]\n",
    "    if len(cluster_points) > 0:\n",
    "        centroid = np.mean(cluster_points, axis=0)\n",
    "        final_centroids.append(centroid)\n",
    "    else:\n",
    "        # If no points in this cluster, use a placeholder (shouldn't happen)\n",
    "        final_centroids.append(np.zeros(train_pca.shape[1]))\n",
    "\n",
    "final_centroids = np.array(final_centroids)\n",
    "\n",
    "print(f\"✓ Computed {len(final_centroids)} centroids in full PCA space\")\n",
    "print(f\"  Centroid shape: {final_centroids[0].shape}\")\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# TRAINING VARIANCES\n",
    "# ============================================================\n",
    "train_variances_final = calculate_within_cluster_variance(train_pca, train_final_clusters, final_centroids)\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# TEST VARIANCES\n",
    "# ============================================================\n",
    "test_data = pca_test_df.values\n",
    "test_final_clusters = processed_patient['Final_Cluster'].values\n",
    "\n",
    "test_variances_final = calculate_within_cluster_variance(test_data, test_final_clusters, final_centroids)\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# COMPARISON\n",
    "# ============================================================\n",
    "print(\"\\nWithin-cluster variance comparison (Final 8 clusters):\")\n",
    "print(f\"{'Cluster':<10} {'Train Variance':<20} {'Test Variance':<20} {'% Change':<15}\")\n",
    "print(\"-\"*75)\n",
    "\n",
    "for cluster_id in sorted(train_variances_final.keys()):\n",
    "    train_var = train_variances_final[cluster_id]\n",
    "    test_var = test_variances_final.get(cluster_id, np.nan)\n",
    "    \n",
    "    if not np.isnan(test_var):\n",
    "        pct_change = ((test_var - train_var) / train_var) * 100\n",
    "        status = \"✓ Stable\" if abs(pct_change) < 25 else \"⚠ Check\"\n",
    "        print(f\"{cluster_id:<10} {train_var:<20.4f} {test_var:<20.4f} {pct_change:>+.2f}%  {status}\")\n",
    "    else:\n",
    "        print(f\"{cluster_id:<10} {train_var:<20.4f} {'No test samples':<20} {'N/A':<15}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4f20f956",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mean distance to assigned centroid:\n",
      "  Training: 3.8946\n",
      "  Test: 3.6849\n"
     ]
    }
   ],
   "source": [
    "# How far are test patients from their assigned centroids?\n",
    "test_distances_to_assigned = []\n",
    "for idx, cluster_id in enumerate(test_final_clusters):\n",
    "    point = test_data[idx]\n",
    "    centroid = final_centroids[cluster_id]\n",
    "    distance = np.linalg.norm(point - centroid)\n",
    "    test_distances_to_assigned.append(distance)\n",
    "\n",
    "# Compare to training\n",
    "train_distances_to_assigned = []\n",
    "for idx, cluster_id in enumerate(train_final_clusters):\n",
    "    point = train_pca[idx]\n",
    "    centroid = final_centroids[cluster_id]\n",
    "    distance = np.linalg.norm(point - centroid)\n",
    "    train_distances_to_assigned.append(distance)\n",
    "\n",
    "print(f\"\\nMean distance to assigned centroid:\")\n",
    "print(f\"  Training: {np.mean(train_distances_to_assigned):.4f}\")\n",
    "print(f\"  Test: {np.mean(test_distances_to_assigned):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "641414cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Silhouette Score (measures cluster separation):\n",
      "  Training: 0.1142\n",
      "  Test: 0.1135\n",
      "  Difference: 0.0007\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "train_silhouette = silhouette_score(train_pca, train_final_clusters)\n",
    "test_silhouette = silhouette_score(test_data, test_final_clusters)\n",
    "\n",
    "print(f\"\\nSilhouette Score (measures cluster separation):\")\n",
    "print(f\"  Training: {train_silhouette:.4f}\")\n",
    "print(f\"  Test: {test_silhouette:.4f}\")\n",
    "print(f\"  Difference: {abs(train_silhouette - test_silhouette):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "625be92a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cluster    Train %      Test %       Diff      \n",
      "0          33.90        33.90        +0.00%\n",
      "1          16.21        16.29        +0.07%\n",
      "2          4.35         3.43         -0.92%\n",
      "3          6.10         5.14         -0.96%\n",
      "4          0.79         0.67         -0.13%\n",
      "5          11.51        13.05        +1.54%\n",
      "6          11.64        11.24        -0.40%\n",
      "7          15.48        16.29        +0.80%\n"
     ]
    }
   ],
   "source": [
    "train_dist = pd.Series(train_final_clusters).value_counts(normalize=True).sort_index() * 100\n",
    "test_dist = pd.Series(test_final_clusters).value_counts(normalize=True).sort_index() * 100\n",
    "\n",
    "print(f\"\\n{'Cluster':<10} {'Train %':<12} {'Test %':<12} {'Diff':<10}\")\n",
    "for c in range(8):\n",
    "    t_train = train_dist.get(c, 0)\n",
    "    t_test = test_dist.get(c, 0)\n",
    "    print(f\"{c:<10} {t_train:<12.2f} {t_test:<12.2f} {t_test-t_train:>+.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25bb1dbf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
